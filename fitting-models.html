<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capitulo 5 Ajustar modelos a datos | Statistical Thinking for the 21st Century</title>
  <meta name="description" content="A book about statistics." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Capitulo 5 Ajustar modelos a datos | Statistical Thinking for the 21st Century" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A book about statistics." />
  <meta name="github-repo" content="poldrack/psych10-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capitulo 5 Ajustar modelos a datos | Statistical Thinking for the 21st Century" />
  
  <meta name="twitter:description" content="A book about statistics." />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="data-visualization.html"/>
<link rel="next" href="probability.html"/>
<script src="book_assets/header-attrs-2.7/header-attrs.js"></script>
<script src="book_assets/jquery-2.2.3/jquery.min.js"></script>
<link href="book_assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-129414074-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-129414074-1');
</script>



<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefacio</a>
<ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#por-qué-existe-este-libro"><i class="fa fa-check"></i><b>0.1</b> ¿Por qué existe este libro?</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#la-era-dorada-de-la-información"><i class="fa fa-check"></i><b>0.2</b> La era dorada de la información</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#la-importancia-de-hacer-estadísticas"><i class="fa fa-check"></i><b>0.3</b> La importancia de hacer estadísticas</a></li>
<li class="chapter" data-level="0.4" data-path="index.html"><a href="index.html#un-libro-de-código-abierto-open-source"><i class="fa fa-check"></i><b>0.4</b> Un libro de código abierto (open source)</a></li>
<li class="chapter" data-level="0.5" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>0.5</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introducción.html"><a href="introducción.html"><i class="fa fa-check"></i><b>1</b> Introducción</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introducción.html"><a href="introducción.html#qué-es-el-pensamiento-estadístico"><i class="fa fa-check"></i><b>1.1</b> ¿Qué es el pensamiento estadístico?</a></li>
<li class="chapter" data-level="1.2" data-path="introducción.html"><a href="introducción.html#lidiar-con-la-ansiedad-estadística"><i class="fa fa-check"></i><b>1.2</b> Lidiar con la ansiedad estadística</a></li>
<li class="chapter" data-level="1.3" data-path="introducción.html"><a href="introducción.html#qué-puede-hacer-la-estadística-por-nosotres"><i class="fa fa-check"></i><b>1.3</b> ¿Qué puede hacer la estadística por nosotres?</a></li>
<li class="chapter" data-level="1.4" data-path="introducción.html"><a href="introducción.html#las-grandes-ideas-de-la-estadística"><i class="fa fa-check"></i><b>1.4</b> Las grandes ideas de la estadística</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="introducción.html"><a href="introducción.html#aprendiendo-de-los-datos"><i class="fa fa-check"></i><b>1.4.1</b> Aprendiendo de los datos</a></li>
<li class="chapter" data-level="1.4.2" data-path="introducción.html"><a href="introducción.html#agregación-aggregation"><i class="fa fa-check"></i><b>1.4.2</b> Agregación (<em>aggregation</em>)</a></li>
<li class="chapter" data-level="1.4.3" data-path="introducción.html"><a href="introducción.html#incertidumbre"><i class="fa fa-check"></i><b>1.4.3</b> Incertidumbre</a></li>
<li class="chapter" data-level="1.4.4" data-path="introducción.html"><a href="introducción.html#muestreo-de-una-población"><i class="fa fa-check"></i><b>1.4.4</b> Muestreo de una población</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introducción.html"><a href="introducción.html#causalidad-y-estadística"><i class="fa fa-check"></i><b>1.5</b> Causalidad y estadística</a></li>
<li class="chapter" data-level="1.6" data-path="introducción.html"><a href="introducción.html#objetivos-de-aprendizaje"><i class="fa fa-check"></i><b>1.6</b> Objetivos de aprendizaje</a></li>
<li class="chapter" data-level="1.7" data-path="introducción.html"><a href="introducción.html#lecturas-sugeridas"><i class="fa fa-check"></i><b>1.7</b> Lecturas sugeridas</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="trabajar-con-datos.html"><a href="trabajar-con-datos.html"><i class="fa fa-check"></i><b>2</b> Trabajar con Datos</a>
<ul>
<li class="chapter" data-level="2.1" data-path="trabajar-con-datos.html"><a href="trabajar-con-datos.html#qué-son-los-datos"><i class="fa fa-check"></i><b>2.1</b> ¿Qué son los datos?</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="trabajar-con-datos.html"><a href="trabajar-con-datos.html#datos-cualitativos"><i class="fa fa-check"></i><b>2.1.1</b> Datos Cualitativos</a></li>
<li class="chapter" data-level="2.1.2" data-path="trabajar-con-datos.html"><a href="trabajar-con-datos.html#datos-cuantitativos"><i class="fa fa-check"></i><b>2.1.2</b> Datos cuantitativos</a></li>
<li class="chapter" data-level="2.1.3" data-path="trabajar-con-datos.html"><a href="trabajar-con-datos.html#tipos-de-números"><i class="fa fa-check"></i><b>2.1.3</b> Tipos de números</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="trabajar-con-datos.html"><a href="trabajar-con-datos.html#mediciones-discretas-versus-continuas"><i class="fa fa-check"></i><b>2.2</b> Mediciones Discretas versus Continuas</a></li>
<li class="chapter" data-level="2.3" data-path="trabajar-con-datos.html"><a href="trabajar-con-datos.html#qué-constituye-a-una-buena-medición"><i class="fa fa-check"></i><b>2.3</b> ¿Qué constituye a una buena medición?</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="trabajar-con-datos.html"><a href="trabajar-con-datos.html#confiabilidad"><i class="fa fa-check"></i><b>2.3.1</b> Confiabilidad</a></li>
<li class="chapter" data-level="2.3.2" data-path="trabajar-con-datos.html"><a href="trabajar-con-datos.html#validez"><i class="fa fa-check"></i><b>2.3.2</b> Validez</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="trabajar-con-datos.html"><a href="trabajar-con-datos.html#objetivos-de-aprendizaje-1"><i class="fa fa-check"></i><b>2.4</b> Objetivos de aprendizaje</a></li>
<li class="chapter" data-level="2.5" data-path="trabajar-con-datos.html"><a href="trabajar-con-datos.html#lecturas-sugeridas-1"><i class="fa fa-check"></i><b>2.5</b> Lecturas sugeridas</a></li>
<li class="chapter" data-level="2.6" data-path="trabajar-con-datos.html"><a href="trabajar-con-datos.html#apéndice"><i class="fa fa-check"></i><b>2.6</b> Apéndice</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="trabajar-con-datos.html"><a href="trabajar-con-datos.html#escalas-de-medición"><i class="fa fa-check"></i><b>2.6.1</b> Escalas de medición</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="resumir-datos.html"><a href="resumir-datos.html"><i class="fa fa-check"></i><b>3</b> Resumir datos</a>
<ul>
<li class="chapter" data-level="3.1" data-path="resumir-datos.html"><a href="resumir-datos.html#por-qué-resumir-datos"><i class="fa fa-check"></i><b>3.1</b> ¿Por qué resumir datos?</a></li>
<li class="chapter" data-level="3.2" data-path="resumir-datos.html"><a href="resumir-datos.html#resumiendo-datos-usando-tablas"><i class="fa fa-check"></i><b>3.2</b> Resumiendo datos usando tablas</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="resumir-datos.html"><a href="resumir-datos.html#frequency-distributions"><i class="fa fa-check"></i><b>3.2.1</b> Distribuciones de frecuencias</a></li>
<li class="chapter" data-level="3.2.2" data-path="resumir-datos.html"><a href="resumir-datos.html#cumulative-distributions"><i class="fa fa-check"></i><b>3.2.2</b> Distribuciones acumuladas</a></li>
<li class="chapter" data-level="3.2.3" data-path="resumir-datos.html"><a href="resumir-datos.html#plotting-histograms"><i class="fa fa-check"></i><b>3.2.3</b> Graficar histogramas</a></li>
<li class="chapter" data-level="3.2.4" data-path="resumir-datos.html"><a href="resumir-datos.html#bins-de-un-histograma"><i class="fa fa-check"></i><b>3.2.4</b> Bins de un histograma</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="resumir-datos.html"><a href="resumir-datos.html#representaciones-idealizadas-de-distribuciones"><i class="fa fa-check"></i><b>3.3</b> Representaciones idealizadas de distribuciones</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="resumir-datos.html"><a href="resumir-datos.html#asimetría-sesgo"><i class="fa fa-check"></i><b>3.3.1</b> Asimetría (sesgo)</a></li>
<li class="chapter" data-level="3.3.2" data-path="resumir-datos.html"><a href="resumir-datos.html#distribuciones-con-colas-largas"><i class="fa fa-check"></i><b>3.3.2</b> Distribuciones con colas largas</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="resumir-datos.html"><a href="resumir-datos.html#objetivos-de-aprendizaje-2"><i class="fa fa-check"></i><b>3.4</b> Objetivos de aprendizaje</a></li>
<li class="chapter" data-level="3.5" data-path="resumir-datos.html"><a href="resumir-datos.html#lecturas-sugeridas-2"><i class="fa fa-check"></i><b>3.5</b> Lecturas sugeridas</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-visualization.html"><a href="data-visualization.html"><i class="fa fa-check"></i><b>4</b> Visualización de Datos</a>
<ul>
<li class="chapter" data-level="4.1" data-path="data-visualization.html"><a href="data-visualization.html#anatomía-de-una-gráfica"><i class="fa fa-check"></i><b>4.1</b> Anatomía de una gráfica</a></li>
<li class="chapter" data-level="4.2" data-path="data-visualization.html"><a href="data-visualization.html#principios-de-una-buena-visibilización"><i class="fa fa-check"></i><b>4.2</b> Principios de una buena visibilización</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="data-visualization.html"><a href="data-visualization.html#muestra-los-datos-y-haz-que-destaquen"><i class="fa fa-check"></i><b>4.2.1</b> Muestra los datos y haz que destaquen</a></li>
<li class="chapter" data-level="4.2.2" data-path="data-visualization.html"><a href="data-visualization.html#maximizar-la-porporción-datostinta-dataink-ratio"><i class="fa fa-check"></i><b>4.2.2</b> Maximizar la porporción datos/tinta (data/ink ratio)</a></li>
<li class="chapter" data-level="4.2.3" data-path="data-visualization.html"><a href="data-visualization.html#evita-gráficas-basura"><i class="fa fa-check"></i><b>4.2.3</b> Evita gráficas basura</a></li>
<li class="chapter" data-level="4.2.4" data-path="data-visualization.html"><a href="data-visualization.html#evita-distorsionar-los-datos"><i class="fa fa-check"></i><b>4.2.4</b> Evita distorsionar los datos</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="data-visualization.html"><a href="data-visualization.html#acomodando-las-limitaciones-humanas"><i class="fa fa-check"></i><b>4.3</b> Acomodando las limitaciones humanas</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="data-visualization.html"><a href="data-visualization.html#limitaciones-perceptuales"><i class="fa fa-check"></i><b>4.3.1</b> Limitaciones perceptuales</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="data-visualization.html"><a href="data-visualization.html#corrigiendo-otros-factores"><i class="fa fa-check"></i><b>4.4</b> Corrigiendo otros factores</a></li>
<li class="chapter" data-level="4.5" data-path="data-visualization.html"><a href="data-visualization.html#objetivos-de-aprendizaje-3"><i class="fa fa-check"></i><b>4.5</b> Objetivos de aprendizaje</a></li>
<li class="chapter" data-level="4.6" data-path="data-visualization.html"><a href="data-visualization.html#lecturas-y-videos-sugeridos"><i class="fa fa-check"></i><b>4.6</b> Lecturas y videos sugeridos</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="fitting-models.html"><a href="fitting-models.html"><i class="fa fa-check"></i><b>5</b> Ajustar modelos a datos</a>
<ul>
<li class="chapter" data-level="5.1" data-path="fitting-models.html"><a href="fitting-models.html#qué-es-un-modelo"><i class="fa fa-check"></i><b>5.1</b> ¿Qué es un modelo?</a></li>
<li class="chapter" data-level="5.2" data-path="fitting-models.html"><a href="fitting-models.html#modelado-estadístico-un-ejemplo"><i class="fa fa-check"></i><b>5.2</b> Modelado estadístico: Un ejemplo</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="fitting-models.html"><a href="fitting-models.html#mejorando-nuestro-modelo"><i class="fa fa-check"></i><b>5.2.1</b> Mejorando nuestro modelo</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="fitting-models.html"><a href="fitting-models.html#qué-hace-que-un-modelo-sea-bueno"><i class="fa fa-check"></i><b>5.3</b> ¿Qué hace que un modelo sea “bueno”?</a></li>
<li class="chapter" data-level="5.4" data-path="fitting-models.html"><a href="fitting-models.html#overfitting"><i class="fa fa-check"></i><b>5.4</b> ¿Un modelo puede ser demasiado bueno?</a></li>
<li class="chapter" data-level="5.5" data-path="fitting-models.html"><a href="fitting-models.html#el-modelo-más-simple-la-media"><i class="fa fa-check"></i><b>5.5</b> El modelo más simple: La media</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="fitting-models.html"><a href="fitting-models.html#la-mediana"><i class="fa fa-check"></i><b>5.5.1</b> La mediana</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="fitting-models.html"><a href="fitting-models.html#la-moda"><i class="fa fa-check"></i><b>5.6</b> La moda</a></li>
<li class="chapter" data-level="5.7" data-path="fitting-models.html"><a href="fitting-models.html#variabilidad-qué-tan-bien-se-ajusta-la-media-a-los-datos"><i class="fa fa-check"></i><b>5.7</b> Variabilidad: ¿Qué tan bien se ajusta la media a los datos?</a></li>
<li class="chapter" data-level="5.8" data-path="fitting-models.html"><a href="fitting-models.html#usar-simulaciones-para-entender-la-estadística"><i class="fa fa-check"></i><b>5.8</b> Usar simulaciones para entender la estadística</a></li>
<li class="chapter" data-level="5.9" data-path="fitting-models.html"><a href="fitting-models.html#puntajes-z"><i class="fa fa-check"></i><b>5.9</b> Puntajes Z</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="fitting-models.html"><a href="fitting-models.html#interpretando-puntajes-z"><i class="fa fa-check"></i><b>5.9.1</b> Interpretando Puntajes Z</a></li>
<li class="chapter" data-level="5.9.2" data-path="fitting-models.html"><a href="fitting-models.html#puntajes-estandarizados"><i class="fa fa-check"></i><b>5.9.2</b> Puntajes Estandarizados</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="fitting-models.html"><a href="fitting-models.html#objetivos-de-aprendizaje-4"><i class="fa fa-check"></i><b>5.10</b> Objetivos de aprendizaje</a></li>
<li class="chapter" data-level="5.11" data-path="fitting-models.html"><a href="fitting-models.html#apéndice-1"><i class="fa fa-check"></i><b>5.11</b> Apéndice</a>
<ul>
<li class="chapter" data-level="5.11.1" data-path="fitting-models.html"><a href="fitting-models.html#proof-that-the-sum-of-errors-from-the-mean-is-zero"><i class="fa fa-check"></i><b>5.11.1</b> Proof that the sum of errors from the Mean is zero”</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>6</b> Probabilidad</a>
<ul>
<li class="chapter" data-level="6.1" data-path="probability.html"><a href="probability.html#qué-es-la-probabilidad"><i class="fa fa-check"></i><b>6.1</b> ¿Qué es la probabilidad?</a></li>
<li class="chapter" data-level="6.2" data-path="probability.html"><a href="probability.html#cómo-determinamos-probabilidades"><i class="fa fa-check"></i><b>6.2</b> ¿Cómo determinamos probabilidades?</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="probability.html"><a href="probability.html#creencia-personal"><i class="fa fa-check"></i><b>6.2.1</b> Creencia personal</a></li>
<li class="chapter" data-level="6.2.2" data-path="probability.html"><a href="probability.html#empirical-frequency"><i class="fa fa-check"></i><b>6.2.2</b> Frecuencia empírica</a></li>
<li class="chapter" data-level="6.2.3" data-path="probability.html"><a href="probability.html#probabilidad-clásica"><i class="fa fa-check"></i><b>6.2.3</b> Probabilidad clásica</a></li>
<li class="chapter" data-level="6.2.4" data-path="probability.html"><a href="probability.html#resolviendo-el-problema-de-de-méré"><i class="fa fa-check"></i><b>6.2.4</b> Resolviendo el problema de de Méré</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="probability.html"><a href="probability.html#distribuciones-de-probabilidad"><i class="fa fa-check"></i><b>6.3</b> Distribuciones de probabilidad</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="probability.html"><a href="probability.html#distribuciones-de-probabilidad-acumuladas"><i class="fa fa-check"></i><b>6.3.1</b> Distribuciones de probabilidad acumuladas</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="probability.html"><a href="probability.html#conditional-probability"><i class="fa fa-check"></i><b>6.4</b> Probabilidad condicional</a></li>
<li class="chapter" data-level="6.5" data-path="probability.html"><a href="probability.html#calcular-probabilidades-condicionales-a-partir-de-los-datos"><i class="fa fa-check"></i><b>6.5</b> Calcular probabilidades condicionales a partir de los datos</a></li>
<li class="chapter" data-level="6.6" data-path="probability.html"><a href="probability.html#independencia"><i class="fa fa-check"></i><b>6.6</b> Independencia</a></li>
<li class="chapter" data-level="6.7" data-path="probability.html"><a href="probability.html#bayestheorem"><i class="fa fa-check"></i><b>6.7</b> Invertir una probabilidad condicional: regla de Bayes</a></li>
<li class="chapter" data-level="6.8" data-path="probability.html"><a href="probability.html#aprender-de-los-datos"><i class="fa fa-check"></i><b>6.8</b> Aprender de los datos</a></li>
<li class="chapter" data-level="6.9" data-path="probability.html"><a href="probability.html#posibilidades-odds-y-razón-de-posibilidades-odds-ratios"><i class="fa fa-check"></i><b>6.9</b> Posibilidades (odds) y razón de posibilidades (odds ratios)</a></li>
<li class="chapter" data-level="6.10" data-path="probability.html"><a href="probability.html#qué-significan-las-probabilidades"><i class="fa fa-check"></i><b>6.10</b> ¿Qué significan las probabilidades?</a></li>
<li class="chapter" data-level="6.11" data-path="probability.html"><a href="probability.html#objetivos-de-aprendizaje-5"><i class="fa fa-check"></i><b>6.11</b> Objetivos de Aprendizaje</a></li>
<li class="chapter" data-level="6.12" data-path="probability.html"><a href="probability.html#lecturas-sugeridas-3"><i class="fa fa-check"></i><b>6.12</b> Lecturas sugeridas</a></li>
<li class="chapter" data-level="6.13" data-path="probability.html"><a href="probability.html#apéndice-2"><i class="fa fa-check"></i><b>6.13</b> Apéndice</a>
<ul>
<li class="chapter" data-level="6.13.1" data-path="probability.html"><a href="probability.html#derivación-de-la-regla-de-bayes"><i class="fa fa-check"></i><b>6.13.1</b> Derivación de la regla de Bayes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="sampling.html"><a href="sampling.html"><i class="fa fa-check"></i><b>7</b> Muestreo</a>
<ul>
<li class="chapter" data-level="7.1" data-path="sampling.html"><a href="sampling.html#how-do-we-sample"><i class="fa fa-check"></i><b>7.1</b> ¿Cómo hacemos una muestra?</a></li>
<li class="chapter" data-level="7.2" data-path="sampling.html"><a href="sampling.html#samplingerror"><i class="fa fa-check"></i><b>7.2</b> Error de muestreo</a></li>
<li class="chapter" data-level="7.3" data-path="sampling.html"><a href="sampling.html#standard-error-of-the-mean"><i class="fa fa-check"></i><b>7.3</b> Error estándar de la media</a></li>
<li class="chapter" data-level="7.4" data-path="sampling.html"><a href="sampling.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>7.4</b> El teorema del límite central</a></li>
<li class="chapter" data-level="7.5" data-path="sampling.html"><a href="sampling.html#confidence-intervals"><i class="fa fa-check"></i><b>7.5</b> Intervalos de confianza</a></li>
<li class="chapter" data-level="7.6" data-path="sampling.html"><a href="sampling.html#objetivos-de-aprendizaje-6"><i class="fa fa-check"></i><b>7.6</b> Objetivos de aprendizaje</a></li>
<li class="chapter" data-level="7.7" data-path="sampling.html"><a href="sampling.html#lecturas-sugeridas-4"><i class="fa fa-check"></i><b>7.7</b> Lecturas sugeridas</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html"><i class="fa fa-check"></i><b>8</b> Remuestreo y Simulación</a>
<ul>
<li class="chapter" data-level="8.1" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#simulación-monte-carlo"><i class="fa fa-check"></i><b>8.1</b> Simulación Monte Carlo</a></li>
<li class="chapter" data-level="8.2" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#aleatoriedad-en-estadística"><i class="fa fa-check"></i><b>8.2</b> Aleatoriedad en Estadística</a></li>
<li class="chapter" data-level="8.3" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#generando-números-aleatorios"><i class="fa fa-check"></i><b>8.3</b> Generando números aleatorios</a></li>
<li class="chapter" data-level="8.4" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#utilizando-una-simulación-con-el-método-de-montecarlo"><i class="fa fa-check"></i><b>8.4</b> Utilizando una simulación con el Método de Montecarlo</a></li>
<li class="chapter" data-level="8.5" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#usando-simulaciones-para-estadística-the-bootstrap"><i class="fa fa-check"></i><b>8.5</b> Usando simulaciones para estadística: The bootstrap</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#calculando-el-bootstrap"><i class="fa fa-check"></i><b>8.5.1</b> Calculando el bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#objetivos-de-aprendizaje-7"><i class="fa fa-check"></i><b>8.6</b> Objetivos de aprendizaje</a></li>
<li class="chapter" data-level="8.7" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#lecturas-sugeridas-5"><i class="fa fa-check"></i><b>8.7</b> Lecturas sugeridas</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>9</b> Prueba de hipótesis</a>
<ul>
<li class="chapter" data-level="9.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#prueba-estadística-de-hipótesis-nula-null-hypothesis-statistical-testing-nhst"><i class="fa fa-check"></i><b>9.1</b> Prueba Estadística de Hipótesis Nula (Null Hypothesis Statistical Testing, NHST)</a></li>
<li class="chapter" data-level="9.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#prueba-estadística-de-hipótesis-nula-un-ejemplo"><i class="fa fa-check"></i><b>9.2</b> Prueba estadística de hipótesis nula: Un ejemplo</a></li>
<li class="chapter" data-level="9.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#el-proceso-de-la-prueba-de-hipótesis-nula"><i class="fa fa-check"></i><b>9.3</b> El proceso de la prueba de hipótesis nula</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#paso-1-formular-una-hipótesis-de-interés"><i class="fa fa-check"></i><b>9.3.1</b> Paso 1: Formular una hipótesis de interés</a></li>
<li class="chapter" data-level="9.3.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#paso-2-especifica-las-hipótesis-nula-y-alternativa"><i class="fa fa-check"></i><b>9.3.2</b> Paso 2: Especifica las hipótesis nula y alternativa</a></li>
<li class="chapter" data-level="9.3.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#paso-3-recolectar-datos"><i class="fa fa-check"></i><b>9.3.3</b> Paso 3: Recolectar datos</a></li>
<li class="chapter" data-level="9.3.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#paso-4-ajusta-un-modelo-a-los-datos-y-calcula-el-estadístico-de-prueba"><i class="fa fa-check"></i><b>9.3.4</b> Paso 4: Ajusta un modelo a los datos y calcula el estadístico de prueba</a></li>
<li class="chapter" data-level="9.3.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#paso-5-determinar-la-probabilidad-de-los-datos-bajo-la-hipótesis-nula"><i class="fa fa-check"></i><b>9.3.5</b> Paso 5: Determinar la probabilidad de los datos bajo la hipótesis nula</a></li>
<li class="chapter" data-level="9.3.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#paso-6-evalúa-la-significatividad-estadística-del-resultado"><i class="fa fa-check"></i><b>9.3.6</b> Paso 6: Evalúa la “significatividad estadística” del resultado</a></li>
<li class="chapter" data-level="9.3.7" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#qué-significa-un-resultado-significativo"><i class="fa fa-check"></i><b>9.3.7</b> ¿Qué significa un resultado significativo?</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#nhst-en-un-contexto-moderno-pruebas-múltiples"><i class="fa fa-check"></i><b>9.4</b> NHST en un contexto moderno: Pruebas múltiples</a></li>
<li class="chapter" data-level="9.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#objetivos-de-aprendizaje-8"><i class="fa fa-check"></i><b>9.5</b> Objetivos de aprendizaje</a></li>
<li class="chapter" data-level="9.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#lecturas-sugeridas-6"><i class="fa fa-check"></i><b>9.6</b> Lecturas sugeridas</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html"><i class="fa fa-check"></i><b>10</b> Cuantificar efectos y diseñar estudios</a>
<ul>
<li class="chapter" data-level="10.1" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#intervalos-de-confianza"><i class="fa fa-check"></i><b>10.1</b> Intervalos de confianza</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#intervalos-de-confianza-usando-la-distribución-normal"><i class="fa fa-check"></i><b>10.1.1</b> Intervalos de confianza usando la distribución normal</a></li>
<li class="chapter" data-level="10.1.2" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#intervalos-de-confianza-utilizando-la-distribución-t"><i class="fa fa-check"></i><b>10.1.2</b> Intervalos de confianza utilizando la distribución t</a></li>
<li class="chapter" data-level="10.1.3" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#intervalos-de-confianza-y-tamaño-de-muestra"><i class="fa fa-check"></i><b>10.1.3</b> Intervalos de confianza y tamaño de muestra</a></li>
<li class="chapter" data-level="10.1.4" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#calcular-el-intervalo-de-confianza-utilizando-bootstrap"><i class="fa fa-check"></i><b>10.1.4</b> Calcular el intervalo de confianza utilizando “bootstrap”</a></li>
<li class="chapter" data-level="10.1.5" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#relación-de-los-intervalos-de-confianza-con-la-prueba-de-hipótesis"><i class="fa fa-check"></i><b>10.1.5</b> Relación de los intervalos de confianza con la prueba de hipótesis</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#tamaño-de-efecto-effect-sizes"><i class="fa fa-check"></i><b>10.2</b> Tamaño de efecto (effect sizes)</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#d-de-cohen"><i class="fa fa-check"></i><b>10.2.1</b> D de Cohen</a></li>
<li class="chapter" data-level="10.2.2" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#r-de-pearson"><i class="fa fa-check"></i><b>10.2.2</b> r de Pearson</a></li>
<li class="chapter" data-level="10.2.3" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#razón-de-probabilidades-odds-ratio"><i class="fa fa-check"></i><b>10.2.3</b> Razón de probabilidades (odds ratio)</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#statistical-power"><i class="fa fa-check"></i><b>10.3</b> Poder estadístico</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#análisis-de-poder"><i class="fa fa-check"></i><b>10.3.1</b> Análisis de poder</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#objetivos-de-aprendizaje-9"><i class="fa fa-check"></i><b>10.4</b> Objetivos de aprendizaje</a></li>
<li class="chapter" data-level="10.5" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#lecturas-sugeridas-7"><i class="fa fa-check"></i><b>10.5</b> Lecturas sugeridas</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html"><i class="fa fa-check"></i><b>11</b> Estadística Bayesiana</a>
<ul>
<li class="chapter" data-level="11.1" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#modelos-generativos"><i class="fa fa-check"></i><b>11.1</b> Modelos Generativos</a></li>
<li class="chapter" data-level="11.2" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#el-teorema-de-bayes-y-la-inferencia-inversa"><i class="fa fa-check"></i><b>11.2</b> El Teorema de Bayes y la Inferencia Inversa</a></li>
<li class="chapter" data-level="11.3" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#doing-bayesian-estimation"><i class="fa fa-check"></i><b>11.3</b> Haciendo estimaciones Bayesianas</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#especificar-la-probabilidad-previa"><i class="fa fa-check"></i><b>11.3.1</b> Especificar la probabilidad previa</a></li>
<li class="chapter" data-level="11.3.2" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#recolectar-los-datos"><i class="fa fa-check"></i><b>11.3.2</b> Recolectar los datos</a></li>
<li class="chapter" data-level="11.3.3" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#calcular-la-probabilidad"><i class="fa fa-check"></i><b>11.3.3</b> Calcular la probabilidad</a></li>
<li class="chapter" data-level="11.3.4" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#calcular-la-probabilidad-marginal"><i class="fa fa-check"></i><b>11.3.4</b> Calcular la probabilidad marginal</a></li>
<li class="chapter" data-level="11.3.5" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#calcular-la-probabilidad-posterior"><i class="fa fa-check"></i><b>11.3.5</b> Calcular la probabilidad posterior</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#estimating-posterior-distributions"><i class="fa fa-check"></i><b>11.4</b> Estimar distribuciones posteriores</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#especificar-la-probabilidad-previa-1"><i class="fa fa-check"></i><b>11.4.1</b> Especificar la probabilidad previa</a></li>
<li class="chapter" data-level="11.4.2" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#recolectar-algunos-datos"><i class="fa fa-check"></i><b>11.4.2</b> Recolectar algunos datos</a></li>
<li class="chapter" data-level="11.4.3" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#calcular-la-probabilidad-1"><i class="fa fa-check"></i><b>11.4.3</b> Calcular la probabilidad</a></li>
<li class="chapter" data-level="11.4.4" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#calcular-la-probabilidad-marginal-1"><i class="fa fa-check"></i><b>11.4.4</b> Calcular la probabilidad marginal</a></li>
<li class="chapter" data-level="11.4.5" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#calculando-la-probabilidad-posterior"><i class="fa fa-check"></i><b>11.4.5</b> Calculando la probabilidad posterior</a></li>
<li class="chapter" data-level="11.4.6" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#estimación-máxima-a-posteriori-map-por-sus-siglas-en-inglés"><i class="fa fa-check"></i><b>11.4.6</b> Estimación máxima a posteriori (MAP, por sus siglas en inglés)</a></li>
<li class="chapter" data-level="11.4.7" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#intervalos-de-credibilidad"><i class="fa fa-check"></i><b>11.4.7</b> Intervalos de credibilidad</a></li>
<li class="chapter" data-level="11.4.8" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#efectos-de-diferentes-probabilidades-previas"><i class="fa fa-check"></i><b>11.4.8</b> Efectos de diferentes probabilidades previas</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#elegir-una-probabilidad-previa"><i class="fa fa-check"></i><b>11.5</b> Elegir una probabilidad previa</a></li>
<li class="chapter" data-level="11.6" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#prueba-de-hipótesis-bayesiana"><i class="fa fa-check"></i><b>11.6</b> Prueba de hipótesis Bayesiana</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#Bayes-factors"><i class="fa fa-check"></i><b>11.6.1</b> Factores de Bayes</a></li>
<li class="chapter" data-level="11.6.2" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#factores-de-bayes-para-hipótesis-estadísticas"><i class="fa fa-check"></i><b>11.6.2</b> Factores de Bayes para hipótesis estadísticas</a></li>
<li class="chapter" data-level="11.6.3" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#evaluar-evidencia-a-favor-de-la-hipótesis-nula"><i class="fa fa-check"></i><b>11.6.3</b> Evaluar evidencia a favor de la hipótesis nula</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#objetivos-de-aprendizaje-10"><i class="fa fa-check"></i><b>11.7</b> Objetivos de aprendizaje</a></li>
<li class="chapter" data-level="11.8" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#suggested-readings"><i class="fa fa-check"></i><b>11.8</b> Suggested readings</a></li>
<li class="chapter" data-level="11.9" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#apéndice-3"><i class="fa fa-check"></i><b>11.9</b> Apéndice:</a>
<ul>
<li class="chapter" data-level="11.9.1" data-path="estadística-bayesiana.html"><a href="estadística-bayesiana.html#muestreo-de-rechazo"><i class="fa fa-check"></i><b>11.9.1</b> Muestreo de rechazo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="modelar-relaciones-categóricas.html"><a href="modelar-relaciones-categóricas.html"><i class="fa fa-check"></i><b>12</b> Modelar relaciones categóricas</a>
<ul>
<li class="chapter" data-level="12.1" data-path="modelar-relaciones-categóricas.html"><a href="modelar-relaciones-categóricas.html#ejemplo-colores-de-dulces"><i class="fa fa-check"></i><b>12.1</b> Ejemplo: Colores de dulces</a></li>
<li class="chapter" data-level="12.2" data-path="modelar-relaciones-categóricas.html"><a href="modelar-relaciones-categóricas.html#chi-squared-test"><i class="fa fa-check"></i><b>12.2</b> Prueba Ji-cuadrada de Pearson</a></li>
<li class="chapter" data-level="12.3" data-path="modelar-relaciones-categóricas.html"><a href="modelar-relaciones-categóricas.html#two-way-test"><i class="fa fa-check"></i><b>12.3</b> Tablas de contingencia y la prueba de dos vías</a></li>
<li class="chapter" data-level="12.4" data-path="modelar-relaciones-categóricas.html"><a href="modelar-relaciones-categóricas.html#residuales-estandarizados"><i class="fa fa-check"></i><b>12.4</b> Residuales estandarizados</a></li>
<li class="chapter" data-level="12.5" data-path="modelar-relaciones-categóricas.html"><a href="modelar-relaciones-categóricas.html#razones-de-posibilidades-odds-ratios"><i class="fa fa-check"></i><b>12.5</b> Razones de posibilidades (odds ratios)</a></li>
<li class="chapter" data-level="12.6" data-path="modelar-relaciones-categóricas.html"><a href="modelar-relaciones-categóricas.html#factores-de-bayes"><i class="fa fa-check"></i><b>12.6</b> Factores de Bayes</a></li>
<li class="chapter" data-level="12.7" data-path="modelar-relaciones-categóricas.html"><a href="modelar-relaciones-categóricas.html#análisis-categórico-más-allá-de-la-tabla-2-x-2"><i class="fa fa-check"></i><b>12.7</b> Análisis categórico más allá de la tabla 2 X 2</a></li>
<li class="chapter" data-level="12.8" data-path="modelar-relaciones-categóricas.html"><a href="modelar-relaciones-categóricas.html#cuídate-de-la-paradoja-de-simpson"><i class="fa fa-check"></i><b>12.8</b> Cuídate de la paradoja de Simpson</a></li>
<li class="chapter" data-level="12.9" data-path="modelar-relaciones-categóricas.html"><a href="modelar-relaciones-categóricas.html#objetivos-de-aprendizaje-11"><i class="fa fa-check"></i><b>12.9</b> Objetivos de aprendizaje</a></li>
<li class="chapter" data-level="12.10" data-path="modelar-relaciones-categóricas.html"><a href="modelar-relaciones-categóricas.html#lecturas-adicionales"><i class="fa fa-check"></i><b>12.10</b> Lecturas adicionales</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html"><i class="fa fa-check"></i><b>13</b> Modelar relaciones continuas</a>
<ul>
<li class="chapter" data-level="13.1" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#un-ejemplo-crímenes-de-odio-y-la-inequidad-de-ingreso"><i class="fa fa-check"></i><b>13.1</b> Un ejemplo: Crímenes de odio y la inequidad de ingreso</a></li>
<li class="chapter" data-level="13.2" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#la-inequidad-de-ingreso-está-relacionada-a-los-crímenes-de-odio"><i class="fa fa-check"></i><b>13.2</b> ¿La inequidad de ingreso está relacionada a los crímenes de odio?</a></li>
<li class="chapter" data-level="13.3" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#covariance-and-correlation"><i class="fa fa-check"></i><b>13.3</b> Covarianza y la correlación</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#prueba-de-hipótesis-para-correlaciones"><i class="fa fa-check"></i><b>13.3.1</b> Prueba de hipótesis para correlaciones</a></li>
<li class="chapter" data-level="13.3.2" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#robust-correlations"><i class="fa fa-check"></i><b>13.3.2</b> Correlaciones Robustas</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#correlación-y-causalidad"><i class="fa fa-check"></i><b>13.4</b> Correlación y causalidad</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#gráficas-causales"><i class="fa fa-check"></i><b>13.4.1</b> Gráficas causales</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#objetivos-de-aprendizaje-12"><i class="fa fa-check"></i><b>13.5</b> Objetivos de aprendizaje</a></li>
<li class="chapter" data-level="13.6" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#lecturas-sugeridas-8"><i class="fa fa-check"></i><b>13.6</b> Lecturas sugeridas</a></li>
<li class="chapter" data-level="13.7" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#apéndice-4"><i class="fa fa-check"></i><b>13.7</b> Apéndice:</a>
<ul>
<li class="chapter" data-level="13.7.1" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#cuantificando-la-inequidad-el-índice-gini"><i class="fa fa-check"></i><b>13.7.1</b> Cuantificando la inequidad: El índice Gini</a></li>
<li class="chapter" data-level="13.7.2" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#análisis-de-correlación-bayesiana"><i class="fa fa-check"></i><b>13.7.2</b> Análisis de correlación bayesiana</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="el-modelo-lineal-general.html"><a href="el-modelo-lineal-general.html"><i class="fa fa-check"></i><b>14</b> El Modelo Lineal General</a>
<ul>
<li class="chapter" data-level="14.1" data-path="el-modelo-lineal-general.html"><a href="el-modelo-lineal-general.html#linear-regression"><i class="fa fa-check"></i><b>14.1</b> Regresión lineal</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="el-modelo-lineal-general.html"><a href="el-modelo-lineal-general.html#regression-to-the-mean"><i class="fa fa-check"></i><b>14.1.1</b> Regresión a la media</a></li>
<li class="chapter" data-level="14.1.2" data-path="el-modelo-lineal-general.html"><a href="el-modelo-lineal-general.html#la-relación-entre-correlación-y-regresión"><i class="fa fa-check"></i><b>14.1.2</b> La relación entre correlación y regresión</a></li>
<li class="chapter" data-level="14.1.3" data-path="el-modelo-lineal-general.html"><a href="el-modelo-lineal-general.html#errores-estándar-de-los-modelos-de-regresión"><i class="fa fa-check"></i><b>14.1.3</b> Errores estándar de los modelos de regresión</a></li>
<li class="chapter" data-level="14.1.4" data-path="el-modelo-lineal-general.html"><a href="el-modelo-lineal-general.html#pruebas-estadísticas-para-los-parámetros-de-la-regresión"><i class="fa fa-check"></i><b>14.1.4</b> Pruebas estadísticas para los parámetros de la regresión</a></li>
<li class="chapter" data-level="14.1.5" data-path="el-modelo-lineal-general.html"><a href="el-modelo-lineal-general.html#cuantificar-la-bondad-de-adjuste-del-modelo"><i class="fa fa-check"></i><b>14.1.5</b> Cuantificar la bondad de adjuste del modelo</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="el-modelo-lineal-general.html"><a href="el-modelo-lineal-general.html#ajustar-modelos-más-complejos"><i class="fa fa-check"></i><b>14.2</b> Ajustar modelos más complejos</a></li>
<li class="chapter" data-level="14.3" data-path="el-modelo-lineal-general.html"><a href="el-modelo-lineal-general.html#interacciones-entre-variables"><i class="fa fa-check"></i><b>14.3</b> Interacciones entre variables</a></li>
<li class="chapter" data-level="14.4" data-path="el-modelo-lineal-general.html"><a href="el-modelo-lineal-general.html#más-allá-de-predictores-y-resultados-lineales"><i class="fa fa-check"></i><b>14.4</b> Más allá de predictores y resultados lineales</a></li>
<li class="chapter" data-level="14.5" data-path="el-modelo-lineal-general.html"><a href="el-modelo-lineal-general.html#model-criticism"><i class="fa fa-check"></i><b>14.5</b> Criticar nuestro modelo y revisar suposiciones</a></li>
<li class="chapter" data-level="14.6" data-path="el-modelo-lineal-general.html"><a href="el-modelo-lineal-general.html#qué-significa-realmente-predecir"><i class="fa fa-check"></i><b>14.6</b> ¿Qué significa realmente “predecir”?</a>
<ul>
<li class="chapter" data-level="14.6.1" data-path="el-modelo-lineal-general.html"><a href="el-modelo-lineal-general.html#cross-validation"><i class="fa fa-check"></i><b>14.6.1</b> Validación cruzada (Cross-validation)</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="el-modelo-lineal-general.html"><a href="el-modelo-lineal-general.html#objetivos-de-aprendizaje-13"><i class="fa fa-check"></i><b>14.7</b> Objetivos de aprendizaje</a></li>
<li class="chapter" data-level="14.8" data-path="el-modelo-lineal-general.html"><a href="el-modelo-lineal-general.html#lecturas-sugeridas-9"><i class="fa fa-check"></i><b>14.8</b> Lecturas sugeridas</a></li>
<li class="chapter" data-level="14.9" data-path="el-modelo-lineal-general.html"><a href="el-modelo-lineal-general.html#apéndice-5"><i class="fa fa-check"></i><b>14.9</b> Apéndice</a>
<ul>
<li class="chapter" data-level="14.9.1" data-path="el-modelo-lineal-general.html"><a href="el-modelo-lineal-general.html#estimar-parámetros-de-una-regresión-lineal"><i class="fa fa-check"></i><b>14.9.1</b> Estimar parámetros de una regresión lineal</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="comparar-medias.html"><a href="comparar-medias.html"><i class="fa fa-check"></i><b>15</b> Comparar medias</a>
<ul>
<li class="chapter" data-level="15.1" data-path="comparar-medias.html"><a href="comparar-medias.html#single-mean"><i class="fa fa-check"></i><b>15.1</b> Probar el valor de una media simple</a></li>
<li class="chapter" data-level="15.2" data-path="comparar-medias.html"><a href="comparar-medias.html#comparing-two-means"><i class="fa fa-check"></i><b>15.2</b> Comparar dos medias</a></li>
<li class="chapter" data-level="15.3" data-path="comparar-medias.html"><a href="comparar-medias.html#ttest-linear-model"><i class="fa fa-check"></i><b>15.3</b> La prueba t como un modelo lineal</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="comparar-medias.html"><a href="comparar-medias.html#tamaños-de-efecto-para-comparar-dos-medias"><i class="fa fa-check"></i><b>15.3.1</b> Tamaños de efecto para comparar dos medias</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="comparar-medias.html"><a href="comparar-medias.html#factores-de-bayes-para-diferencias-entre-medias"><i class="fa fa-check"></i><b>15.4</b> Factores de Bayes para diferencias entre medias</a></li>
<li class="chapter" data-level="15.5" data-path="comparar-medias.html"><a href="comparar-medias.html#paired-ttests"><i class="fa fa-check"></i><b>15.5</b> Comparar observaciones pareadas/relacionadas</a>
<ul>
<li class="chapter" data-level="15.5.1" data-path="comparar-medias.html"><a href="comparar-medias.html#prueba-de-los-signos"><i class="fa fa-check"></i><b>15.5.1</b> Prueba de los signos</a></li>
<li class="chapter" data-level="15.5.2" data-path="comparar-medias.html"><a href="comparar-medias.html#prueba-t-para-muestras-relacionadas-paired-t-test"><i class="fa fa-check"></i><b>15.5.2</b> Prueba t para muestras relacionadas (paired t-test)</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="comparar-medias.html"><a href="comparar-medias.html#comparar-más-de-dos-medias"><i class="fa fa-check"></i><b>15.6</b> Comparar más de dos medias</a>
<ul>
<li class="chapter" data-level="15.6.1" data-path="comparar-medias.html"><a href="comparar-medias.html#ANOVA"><i class="fa fa-check"></i><b>15.6.1</b> Análisis de varianza</a></li>
</ul></li>
<li class="chapter" data-level="15.7" data-path="comparar-medias.html"><a href="comparar-medias.html#objetivos-de-aprendizaje-14"><i class="fa fa-check"></i><b>15.7</b> Objetivos de aprendizaje</a></li>
<li class="chapter" data-level="15.8" data-path="comparar-medias.html"><a href="comparar-medias.html#apéndice-6"><i class="fa fa-check"></i><b>15.8</b> Apéndice</a>
<ul>
<li class="chapter" data-level="15.8.1" data-path="comparar-medias.html"><a href="comparar-medias.html#la-prueba-t-de-muestras-relacionadas-como-un-modelo-lineal"><i class="fa fa-check"></i><b>15.8.1</b> La prueba t de muestras relacionadas como un modelo lineal</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="practical-example.html"><a href="practical-example.html"><i class="fa fa-check"></i><b>16</b> Modelación estadística práctica</a>
<ul>
<li class="chapter" data-level="16.1" data-path="practical-example.html"><a href="practical-example.html#el-proceso-de-modelación-estadística"><i class="fa fa-check"></i><b>16.1</b> El proceso de modelación estadística</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="practical-example.html"><a href="practical-example.html#especificar-nuestra-pregunta-de-interés."><i class="fa fa-check"></i><b>16.1.1</b> 1: Especificar nuestra pregunta de interés.</a></li>
<li class="chapter" data-level="16.1.2" data-path="practical-example.html"><a href="practical-example.html#identificar-o-recolectar-los-datos-apropiados."><i class="fa fa-check"></i><b>16.1.2</b> 2: Identificar o recolectar los datos apropiados.</a></li>
<li class="chapter" data-level="16.1.3" data-path="practical-example.html"><a href="practical-example.html#preparar-los-datos-para-el-análisis."><i class="fa fa-check"></i><b>16.1.3</b> 3: Preparar los datos para el análisis.</a></li>
<li class="chapter" data-level="16.1.4" data-path="practical-example.html"><a href="practical-example.html#determinar-el-modelo-apropiado."><i class="fa fa-check"></i><b>16.1.4</b> 4: Determinar el modelo apropiado.</a></li>
<li class="chapter" data-level="16.1.5" data-path="practical-example.html"><a href="practical-example.html#ajustar-el-modelo-a-los-datos."><i class="fa fa-check"></i><b>16.1.5</b> 5: Ajustar el modelo a los datos.</a></li>
<li class="chapter" data-level="16.1.6" data-path="practical-example.html"><a href="practical-example.html#criticar-el-modelo-para-asegurarnos-que-se-ajusta-apropiadamente."><i class="fa fa-check"></i><b>16.1.6</b> 6: Criticar el modelo para asegurarnos que se ajusta apropiadamente.</a></li>
<li class="chapter" data-level="16.1.7" data-path="practical-example.html"><a href="practical-example.html#probar-hipótesis-y-cuantificar-el-tamaño-del-efecto."><i class="fa fa-check"></i><b>16.1.7</b> 7: Probar hipótesis y cuantificar el tamaño del efecto.</a></li>
<li class="chapter" data-level="16.1.8" data-path="practical-example.html"><a href="practical-example.html#qué-pasa-con-los-posibles-factores-de-confusión-confounds"><i class="fa fa-check"></i><b>16.1.8</b> ¿Qué pasa con los posibles factores de confusión (confounds)?</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="practical-example.html"><a href="practical-example.html#obtener-ayuda"><i class="fa fa-check"></i><b>16.2</b> Obtener ayuda</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html"><i class="fa fa-check"></i><b>17</b> Hacer investigación reproducible</a>
<ul>
<li class="chapter" data-level="17.1" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#cómo-pensamos-que-funciona-la-ciencia"><i class="fa fa-check"></i><b>17.1</b> Cómo pensamos que funciona la ciencia</a></li>
<li class="chapter" data-level="17.2" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#cómo-realmente-funciona-la-ciencia-a-veces"><i class="fa fa-check"></i><b>17.2</b> Cómo realmente funciona la ciencia (a veces)</a></li>
<li class="chapter" data-level="17.3" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#la-crisis-de-reproducibilidad-en-la-ciencia"><i class="fa fa-check"></i><b>17.3</b> La crisis de reproducibilidad en la ciencia</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#valor-predictivo-positivo-y-significatividad-estadística"><i class="fa fa-check"></i><b>17.3.1</b> Valor predictivo positivo y significatividad estadística</a></li>
<li class="chapter" data-level="17.3.2" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#la-maldición-del-ganador"><i class="fa fa-check"></i><b>17.3.2</b> La maldición del ganador</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#prácticas-cuestionables-de-investigación"><i class="fa fa-check"></i><b>17.4</b> Prácticas cuestionables de investigación</a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#esp-o-qrp"><i class="fa fa-check"></i><b>17.4.1</b> ¿ESP o QRP?</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#hacer-investigación-reproducible"><i class="fa fa-check"></i><b>17.5</b> Hacer investigación reproducible</a>
<ul>
<li class="chapter" data-level="17.5.1" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#pre-registro"><i class="fa fa-check"></i><b>17.5.1</b> Pre-registro</a></li>
<li class="chapter" data-level="17.5.2" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#prácticas-reproducibles"><i class="fa fa-check"></i><b>17.5.2</b> Prácticas reproducibles</a></li>
<li class="chapter" data-level="17.5.3" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#replicación"><i class="fa fa-check"></i><b>17.5.3</b> Replicación</a></li>
</ul></li>
<li class="chapter" data-level="17.6" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#hacer-análisis-de-datos-reproducibles"><i class="fa fa-check"></i><b>17.6</b> Hacer análisis de datos reproducibles</a></li>
<li class="chapter" data-level="17.7" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#conclusión-hacer-mejor-ciencia"><i class="fa fa-check"></i><b>17.7</b> Conclusión: Hacer mejor ciencia</a></li>
<li class="chapter" data-level="17.8" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#objetivos-de-aprendizaje-15"><i class="fa fa-check"></i><b>17.8</b> Objetivos de aprendizaje</a></li>
<li class="chapter" data-level="17.9" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#lecturas-sugeridas-10"><i class="fa fa-check"></i><b>17.9</b> Lecturas sugeridas</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Thinking for the 21st Century</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="fitting-models" class="section level1" number="5">
<h1><span class="header-section-number">Capitulo 5</span> Ajustar modelos a datos</h1>
<!--One of the fundamental activities in statistics is creating models that can summarize data using a small set of numbers, thus providing a compact description of the data.  In this chapter we will discuss the concept of a statistical model and how it can be used to describe data.-->
<p>Una de las actividades fundamentales en estadística es crear modelos que puedan resumir datos utilizando un grupo pequeño de números, de esta forma, se provee una descripción compacta de los datos. En este capítulo discutiremos el concepto de lo que es un modelo estadístico y cómo puede ser utilizado para describir datos.</p>
<!--## What is a model?-->
<div id="qué-es-un-modelo" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> ¿Qué es un modelo?</h2>
<!--In the physical world, "models" are generally simplifications of things in the real world that nonetheless convey the essence of the thing being modeled. A model of a building conveys the structure of the building while being small and light enough to pick up with one's hands; a model of a cell in biology is much larger than the actual thing, but again conveys the major parts of the cell and their relationships.-->
<p>En el mundo físico, los “modelos” son generalmente simplificaciones de cosas del mundo real que, no obstante, transmiten la esencia de lo que se está modelando. El modelo de un edificio transmite la escencia de la estructura del edificio mientras es lo suficientemente pequeño y ligero como para que unx lo pueda sostener con las manos; un modelo de una célula de biología es mucho más grande que una célula real, no obstante, transmite la mayoría de las partes de la célula y las relaciones que tienen entre sí.</p>
<!--In statistics, a model is meant to provide a similarly condensed description, but for data rather than for a physical structure. Like physical models, a statistical model is generally much simpler than the data being described; it is meant to capture the structure of the data as simply as possible. In both cases, we realize that the model is a convenient fiction that necessarily glosses over some of the details of the actual thing being modeled. As the statistician George Box famously said: "All models are wrong but some are useful."-->
<p>En estadística, un modelo tiene el propósito de proveer una descripción similar condensada, pero para los datos, en lugar de una estructura física. Como los modelos físicos, un modelo estadístico es generalmente mucho más simple que los datos que están siendo descritos; tiene el propósito de capturar la estructura de los datos de la forma más simple posible. En ambos casos, podemos notar que el modelo es una ficción conveniente que necesariamente pasa por alto algunos detalles de lo que está tratando de representar. Como el estadístico George Box dijo: “Todos los modelos son incorrectos, pero algunos son útiles”.</p>
<!--The basic structure of a statistical model is:-->
<p>La estructura básica de un modelo estadístico es:</p>
<!--$$
data = model + error
$$-->
<p><span class="math display">\[
Datos= modelo + error
\]</span>
<!--This expresses the idea that the data can be described by a statistical model, which expresses what we expect to occur in the data, along with the difference between the model and the data, which we refer to as the *error*.-->
Esto expresa la idea de que los datos pueden ser descritos por un modelo estadístico, el cual expresa qué es lo que esperamos que ocurra en los datos, junto con la diferencia entre el modelo y los datos, a lo cual nos referimos como el <em>error</em>.</p>
<!--## Statistical modeling: An example-->
</div>
<div id="modelado-estadístico-un-ejemplo" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Modelado estadístico: Un ejemplo</h2>
<!--Let's look at an example of fitting a model to data, using the data from NHANES.  In particular, we will try to build a model of the height of children in the NHANES sample. First let's load the data and plot them (see Figure \@ref(fig:childHeight)).-->
<p>Observemos el ejemplo de ajustar un modelo a los datos, utilizando los datos de NHANES. En particular, trataremos de construir un modelo de la altura de lxs niñxs en la muestra de NHANES. Primero vamos a cargar los datos y los graficaremos (ve la Figura <a href="fitting-models.html#fig:childHeight">5.1</a>)..</p>
<div class="figure"><span id="fig:childHeight"></span>
<img src="StatsThinking21_files/figure-html/childHeight-1.png" alt="Histogram of height of children in NHANES." width="384" height="50%" />
<p class="caption">
Figura 5.1: Histogram of height of children in NHANES.
</p>
</div>
<!--Remember that we want to describe the data as simply as possible while still capturing their important features. What is the simplest model we can imagine that might still capture the essence of the data?  How about the most common value in the dataset (which we call the *mode*)?-->
<p>Recuerda que queremos describir los datos de la forma más simple posible mientras que al mismo tiempo capturamos sus características más importantes. ¿Cuál es el modelo más simple que podemos imaginar que posiblemente aún captura la esencia de los datos? ¿Qué te parece el valor más común encontrado en el grupo de datos (el cual llamamos <em>moda</em>)?</p>
<!--This redescribes the entire set of 1691 children in terms of a single number. If we wanted to predict the height of any new children, then our guess would be the same number: 166.5 centimeters.-->
<p>Esto redefine el conjunto de 1691 niñxs en términos de un sólo número. Si quisiéramos predecir la altura de alguno de los nuevos niñxs, entonces nuestra estimación sería el mismo número: 166.5 centímetros.</p>
<p><span class="math display">\[
\hat{height_i} = 166.5
\]</span></p>
<!--We put the hat symbol over the name of the variable to show that this is our *predicted* value.  The error for this individual would then be the difference between the predicted value ($\hat{height_i}$) and their actual height ($height_i$):-->
<p>Ponemos ese símbolo sobre el nombre de la variable para destacar que esta es nuestro valor <em>predicho</em>. El error para este individuo sería entonces la diferencia entre el valor predicho (<span class="math inline">\(\hat{height_i}\)</span>) y la altura real (<span class="math inline">\(height_i\)</span>):</p>
<p><span class="math display">\[
error_i = height_i - \hat{height_i}
\]</span></p>
<!--How good of a model is this?  In general we define the goodness of a model in terms of the error, which represents the difference between model and the data; all things being equal, the model that produces lower error is the better model. (Though as we will see later, all things are usually not equal...)-->
<p>¿Qué tan buen modelo es este? En general definimos qué tan bueno es un modelo en términos del error, el cual representa la diferencia entre el modelo y los datos; todas las cosas siendo iguales, el modelo que produce el error menor es el mejor modelo. (Aunque, como revisaremos más adelante, todas las cosas usualmente no son iguales…).</p>
<!--What we find is that the average individual has a fairly large error of -28.8 centimeters compared to the mode. We would like to have a model where the average error is zero, and it turns out that if we use the arithmetic mean (commonly known as the *average*) as our model then this will be the case.-->
<p>Lo que encontramos es que la persona promedio tiene un margen de error algo grande de -28.8 centímetros comparado con la moda. Nos agradaría tener un modelo en donde el promedio de error es cero, y resulta ser que si utilizamos la media aritmética (comúnmente conocida como la <em>media</em>) como nuestro modelo, entonces este será el caso.</p>
<!--The mean (often denoted by a bar over the variable, such as $\bar{X}$) is the sum of all of the values, divided by the number of values.  Mathematically, we express this as:-->
<p>La media (a menudo representada por una barra sobre la variable, como <span class="math inline">\(\bar{X}\)</span>) es la suma de todos los valores, divididos entre el número de valores. Matemáticamente, expresamos esto como:</p>
<p><span class="math display">\[
\bar{X} = \frac{\sum_{i=1}^{n}x_i}{n}
\]</span></p>
<!--We can prove mathematically that the sum of errors from the mean (and thus the average error) is zero (see the proof at the end of the chapter if you are interested).  Given that the average error is zero, this seems like a better model.-->
<p>Podemos probar matemáticamente que la suma de los errores de la media (y por lo tanto, el promedio de error) es cero (mira la prueba al final de este capítulo si estás interesadx). Dado que el error promedio es cero, este parece ser el mejor modelo.</p>
<div class="figure"><span id="fig:meanError"></span>
<img src="StatsThinking21_files/figure-html/meanError-1.png" alt="Distribution of errors from the mean." width="384" height="50%" />
<p class="caption">
Figura 5.2: Distribution of errors from the mean.
</p>
</div>
<!--Even though the average of errors from the mean is zero, we can see from the histogram in Figure \@ref(fig:meanError) that each individual still has some degree of error; some are positive and some are negative, and those cancel each other out. For this reason, we generally summarize errors in terms of some kind of measure that counts both positive and negative errors as bad.  We could use the absolute value of each error value, but it's more common to use the squared errors, for reasons that we will see later in the course.-->
<p>A pesar de que el promedio de errores de la media es cero, podemos obsevar en el histograma en la Figura <a href="fitting-models.html#fig:meanError">5.2</a> que cada individuo aún tiene cierto grado de error; algunos son positivos y otros son negativos, y esos se cancelan entre ellos. Por esta razón, generalmente resumimos los errores en términos de algún tipo de medición que considera tanto los errores positivos como los negativos como malos. Podríamos usar el valor absoluto de cada error, pero es más común usar los errores al cuadrado, por razones que veremos después en el curso.</p>
<!--There are several common ways to summarize the squared error that you will encounter at various points in this book, so it's important to understand how they relate to one another.  First, we could simply add them up; this is referred to as the *sum of squared errors*.  The reason we don't usually use this is that its magnitude depends on the number of data points, so it can be difficult to interpret unless we are looking at the same number of observations.  Second, we could  take the mean of the squared error values, which is referred to as the *mean squared error (MSE)*.  However, because we squared the values before averaging, they are not on the same scale as the original data; they are in $centimeters^2$.  For this reason, it's also common to take the square root of the MSE, which we refer to as the *root mean squared error (RMSE)*, so that the error is measured in the same units as the original values (in this example, centimeters).-->
<p>Existen varias formas comunes para resumir el error al cuadrado con el que te encontrarás en varios puntos de este libro, por lo que es importante comprender cómo se relacionan entre ellos. En primer instancia, podríamos simplemente sumarlos; esto se conoce como la <em>suma de los errores al cuadrado</em> (<em>sum of squared errors</em>). La razón por la que usualmente no utilizamos este método es porque su magnitud depende del número de datos, por lo que puede ser difícil de interpretar a menos que estemos viendo el mismo número de observaciones. En segundo lugar, podríamos tomar la media de los valores de error al cuadrado, lo cual se conoce como <em>error cuadrático medio (MSE por sus siglas en inglés: mean squared error)</em>. Sin embargo, ya que elevamos al cuadrado los valores antes de promediarlos, no están en la misma escala que los datos originales; están en <span class="math inline">\(centímetros^2\)</span>. Por esta razón, también es común tomar la raíz cuadrada del <em>error cuadrático medio</em>, al cual nos referimos como <em>raíz del error cuadrático medio (RMSE por sus siglas en inglés: root mean squared error)</em>, para que el error sea medido en las mismas unidades que los valores originales (en este ejemplo, centímetros).</p>
<!--The mean has a pretty substantial amount of error -- any individual data point will be about 27 cm from the mean on average -- but it's still much better than the mode, which has a root mean squared error of about 39 cm.-->
<p>La media contiene una cantidad sustancial de error – cualquier punto individual en los datos estará a unos 27 cm de la media en promedio – pero aún así es mucho mejor que la moda, la cual tiene una raíz de error cuadrático medio de unos 39 cm.</p>
<!--### Improving our model-->
<div id="mejorando-nuestro-modelo" class="section level3" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Mejorando nuestro modelo</h3>
<!--Can we imagine a better model? Remember that these data are from all children in the NHANES sample, who vary from 2 to 17 years of age.  Given this wide age range, we might expect that our model of height should also include age. Let's plot the data for height against age, to see if this relationship really exists.-->
<p>¿Podemos imaginar un mejor modelo? Recuerda que estos datos son de todxs lxs niñxs en la muestra NHANES, quienes varían de 2 a 17 años de edad. Dado este amplio rango de edades, esperaríamos que nuestro modelo de estatura también incluyera edad. Grafiquemos los datos de estatura frente a la edad, para ver si realmente existe relación.</p>
<div class="figure"><span id="fig:childHeightLine"></span>
<img src="StatsThinking21_files/figure-html/childHeightLine-1.png" alt="Height of children in NHANES, plotted without a model (A), with a linear model including only age (B) or age and a constant (C), and with a linear model that fits separate effects of age for males and females (D)." width="576" />
<p class="caption">
Figura 5.3: Height of children in NHANES, plotted without a model (A), with a linear model including only age (B) or age and a constant (C), and with a linear model that fits separate effects of age for males and females (D).
</p>
</div>
<!--The black points in Panel A of Figure \@ref(fig:childHeightLine) show individuals in the dataset, and there seems to be a strong relationship between height and age, as we would expect.  Thus, we might build a model that relates height to age:-->
<p>Los puntos negros en el Panel A de la Figura <a href="fitting-models.html#fig:childHeightLine">5.3</a> muestran individuos en el grupo de datos, y parece ser que hay una relación fuerte entre la edad y la estatura, como esperaríamos. Por lo que esperaríamos poder construir un modelo que relacione estatura y edad:</p>
<p><span class="math display">\[
\hat{height_i} =  \beta * age_i
\]</span></p>
<!-- where $\beta$ is a *parameter* that we multiply by age to get the smallest error.   -->
<p>donde <span class="math inline">\(\beta\)</span> es un <em>parámetro</em> que multiplicamos por edad para obtener el error más pequeño.</p>
<!--You may remember from algebra that a line is defined as follows:-->
<p>Puede que recuerdes de álgebra que una línea se define de la siguiente manera:</p>
<p><span class="math display">\[
y = slope*x + intercept
\]</span></p>
<!--If age is the $X$ variable, then that means that our prediction of height from age will be a line with a slope of $\beta$ and an intercept of zero - to see this, let's plot the best fitting line in blue on top of the data (Panel B in Figure \@ref(fig:childHeightLine)). Something is clearly wrong with this model, as the line doesn't seem to follow the data very well.  In fact, the RMSE for this model (39.16) is actually higher than the model that only includes the mean! The problem comes from the fact that our model only includes age, which means that the predicted value of height from the model must take on a value of zero when age is zero.  Even though the data do not include any children with an age of zero, the line is mathematically required to have a y-value of zero when x is zero, which explains why the line is pulled down below the younger datapoints.  We can fix this by including n intercept in our model, which basically represents the estimated height when age is equal to zero; even though an age of zero is not plausible in this dataset, this is a mathematical trick that will allow the model to account for the overall magnitude of the data.  The model is:-->
<p>Si la edad es la variable <span class="math inline">\(X\)</span>, eso quiere decir que nuestra predicción de la altura conforme a la edad será una línea con una pendiente de <span class="math inline">\(\beta\)</span> y una intercepción de cero. Para observar esto, tracemos una línea azul que mejor se acomode sobre los datos (Panel B en Figura <a href="fitting-models.html#fig:childHeightLine">5.3</a>). Algo está claramente mal con este modelo, ya que, la linea no parece seguir los datos muy bien. De hecho, ¡el RMSE para este modelo (39.16) es más alto que el modelo que solamente incluye la media! El problema radica en el hecho de que nuestro modelo solamente incluye la edad, lo cual significa que el valor de la altura predicho por el modelo debe tomar un valor de cero cuando la edad es cero. Aunque los datos no incluyen niñxs con edad de cero, la línea requiere matemáticamente tener un valor “y” de cero cuando “X” es cero, lo cual explica por qué la línea es jalada por debajo de los puntos de datos más bajos (o jóvenes). Podemos arreglar esto al incluir una intercepción (un <em>intercepto</em>) en nuestro modelo, lo cual básicamente representa una altura estimada cuando la edad es igual a cero; aunque una edad de cero no es plausible en este conjunto de datos, este es un truco matemático que permitirá que el modelo tenga en cuenta la magnitud general de los datos.</p>
<p><span class="math display">\[
\hat{height_i} = intercept + \beta * age_i
\]</span></p>
<!--where *intercept* is a constant value added to the prediction for each individual; we call it the intercept because it maps onto the intercept in the equation for a straight line.  We will learn later how it is that we actually compute these parameter values for a particular dataset; for now, we will use the our statistical software to compute the values of the constant and $\beta$ that give us the smallest error for these particular data. Panel C in Figure \@ref(fig:childHeightLine) shows this model applied to the NHANES data, where we see that the line matches the data much better than the one without a constant.-->
<p>donde <em>intercepto</em> (<em>intercept</em>) es un valor constante agregado a la predicción para cada individuo; lo llamamos intercepto porque se mapea en la intersección en la ecuación de la línea recta. Más adelante aprenderemos cómo es que realmente calculamos estos valores de parámetros para un conjunto de datos en particular; por ahora, usaremos nuestro software estadístico para calcular los valores de la constante y de <span class="math inline">\(\beta\)</span> que nos den el error más pequeño para este conjunto de datos en particular. El Panel C en la Figura <a href="fitting-models.html#fig:childHeightLine">5.3</a> muestra este modelo aplicado a los datos de NHANES, en donde podemos observar que la línea coincide con los datos mucho mejor que la que no tiene constante.</p>
<!--Our error is much smaller using this model -- only 8.36 centimeters on average.  Can you think of other variables that might also be related to height? What about gender?  In Panel D of Figure \@ref(fig:childHeightLine) we plot the data with lines fitted separately for males and females. From the plot, it seems that there is a difference between males and females, but it is relatively small and only emerges after the age of puberty.  Let's estimate this model and see how the errors look.  In Figure \@ref(fig:msePlot) we plot the root mean squared error values across the different models. From this we see that the model got a little bit better going from mode to mean, much better going from mean to mean + age, and only very slightly better by including gender as well.-->
<p>Nuestro error es mucho más pequeño utilizando este modelo – sólo 8.36 centímetros en promedio. ¿Puedes pensar en otras variables que también se relacionen con la estatura? ¿Qué hay del género? En el Panel D de la Figura <a href="fitting-models.html#fig:childHeightLine">5.3</a> graficamos los datos con líneas distintas para género masculino y femenino. Observando sólo la gráfica, parece ser que existe una diferencia entre género masculino y femenino, pero es relativamente pequeño y solamente comienza después de la etapa de la pubertad. Estimemos este modelo y veamos cómo se ven los errores. En la Figura <a href="fitting-models.html#fig:msePlot">5.4</a> trazamos los valores de la raíz del error cuadrático medio a través de los diferentes modelos. Aquí podemos ver que el modelo mejoró un poco al pasar de moda a media, posteriormente mejora más al pasar de media a media + edad, y mejora sólo un poco más al incluir el género también.</p>
<div class="figure"><span id="fig:msePlot"></span>
<img src="StatsThinking21_files/figure-html/msePlot-1.png" alt="Mean squared error plotted for each of the models tested above." width="384" height="50%" />
<p class="caption">
Figura 5.4: Mean squared error plotted for each of the models tested above.
</p>
</div>
<!--## What makes a model "good"?-->
</div>
</div>
<div id="qué-hace-que-un-modelo-sea-bueno" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> ¿Qué hace que un modelo sea “bueno”?</h2>
<!--There are generally two different things that we want from our statistical model. First, we want it to describe our data well; that is, we want it to have the lowest possible error when modeling our data.  Second, we want it to generalize well to new datasets; that is, we want its error to be as low as possible when we apply it to a new dataset in order to make a prediction.  It turns out that these two features can often be in conflict.-->
<p>Generalmente hay dos cosas diferentes que queremos de nuestro modelo estadístico. En primer lugar, queremos que describa nuestros datos correctamente; es decir, queremos que tenga el menor error posible cuando modelemos nuestros datos. En segundo lugar, queremos que se generalice bien a nuevas agrupaciones de datos; es decir, queremos que su error sea lo más bajo posible cuando lo apliquemos a una nueva agrupación de datos para poder hacer una predicción. Resulta ser que estas dos características se encuentran en conflicto constantemente.</p>
<!--To understand this, let's think about where error comes from.  First, it can occur if our model is wrong; for example, if we inaccurately said that height goes down with age instead of going up, then our error will be higher than it would be for the correct model.  Similarly, if there is an important factor that is missing from our model, that will also increase our error (as it did when we left age out of the model for height).  However, error can also occur even when the model is correct, due to random variation in the data, which we often refer to as "measurement error" or "noise".  Sometimes this really is due to error in our measurement -- for example, when the measurements rely on a human, such as using a stopwatch to measure elapsed time in a footrace. In other cases, our measurement device is highly accurate (like a digital scale to measure body weight), but the thing being measured is affected by many different factors that cause it to be variable.  If we knew all of these factors then we could build a more accurate model, but in reality that's rarely possible.-->
<p>Para entender esto, pensemos de dónde viene el error. Puede ocurrir si nuestro modelo está mal, por ejemplo, si de manera incorrecta afirmáramos que la altura declina conforme unx va creciendo en edad, en lugar de decir que la altura crece conforme a unx va cumpliendo más años. En este caso, nuestro error será mucho mayor de lo que sería con el modelo correcto. Similarmente, si hay un factor importante que le hace falta a nuestro modelo, esto también aumentará nuestro error (como ocurrió cuando dejamos de lado la edad para el modelo que generamos para la altura). De cualquier forma, un error también puede ocurrir cuando el modelo es correcto, debido a una posible variación aleatoria en los datos, a la cual solemos referirnos como “error de medición” o “ruido”. A veces esto se debe a un error en nuestra medición – por ejemplo, cuando la medición está bajo el cargo de unx humanx, al usar un cronómetro para medir tiempo transcurrido en una carrera a pie. En otros casos nuestra herramienta de medición puede ser muy exacta (como una escala digital para calcular el peso corporal), pero aquello que está siendo medido puede ser afectado por diversos factores que hacen que varíe. Si conociéramos todos estos factores, entonces podríamos generar un modelo más exacto, pero la realidad es que eso es raramente posible.</p>
<!--Let's use an example to show this.  Rather than using real data, we will generate some data for the example using a computer simulation (about which we will have more to say in a few chapters).  Let's say that we want to understand the relationship between a person's blood alcohol content (BAC) and their reaction time on a simulated driving test.  We can generate some simulated data and plot the relationship (see Panel A of Figure \@ref(fig:BACrt)).-->
<p>Usemos un ejemplo para ilustrar esto. En lugar de utilizar datos reales, generaremos datos para este ejemplo utilizando una simulación por computadora (de la cual hablaremos más adelante en los siguientes capítulos). Digamos que queremos comprender la relación entre el contenido de alcohol en la sangre (“BAC” por sus siglas en inglés: <em>blood alcohol content</em>) y su tiempo de reacción en una prueba de conducir simulada. Podemos generar algunos datos simulados y graficar la relación (ver Panel A de la Figura <a href="fitting-models.html#fig:BACrt">5.5</a>).</p>
<div class="figure"><span id="fig:BACrt"></span>
<img src="StatsThinking21_files/figure-html/BACrt-1.png" alt="Simulated relationship between blood alcohol content and reaction time on a driving test, with best-fitting linear model represented by the line. A: linear relationship with low measurement error.  B: linear relationship with higher measurement error.  C: Nonlinear relationship with low measurement error and (incorrect) linear model" width="576" />
<p class="caption">
Figura 5.5: Simulated relationship between blood alcohol content and reaction time on a driving test, with best-fitting linear model represented by the line. A: linear relationship with low measurement error. B: linear relationship with higher measurement error. C: Nonlinear relationship with low measurement error and (incorrect) linear model
</p>
</div>
<!--In this example, reaction time goes up systematically with blood alcohol content -- the line shows the best fitting model, and we can see that there is very little error, which is evident in the fact that all of the points are very close to the line.-->
<p>En este ejemplo, el tiempo de reacción sube sistemáticamente con el contenido de alcohol en la sangre – la línea muestra el modelo más adecuado, y podemos ver que hay un margen de error pequeño, el cual se evidencia en el hecho de que todos los puntos están muy cerca de la línea.</p>
<!--We could also imagine data that show the same linear relationship, but have much more error, as in Panel B of Figure \@ref(fig:BACrt). Here we see that there is still a systematic increase of reaction time with BAC, but it's much more variable across individuals.-->
<p>También podemos pensar en datos que muestren la misma relación linear, pero que tengan un mayor margen de error, como en el Panel B de la Figura <a href="fitting-models.html#fig:BACrt">5.5</a>. Aquí podemos ver que aún hay un incremento sistemático del tiempo de reacción con el contenido de alcohol en la sangre (BAC), pero es mucho más variable a lo largo de lxs individuos.</p>
<!--These were both examples where the *linear model* seems appropriate, and the error reflects noise in our measurement. The linear model specifies that the relationship between two variables follows a straight line. For example, in a linear model, a particularly increase in BAC is always associated with a specific increase in ReactionTime, regardless of the level of BAC.-->
<p>Estos fueron dos ejemplos en donde el <em>modelo lineal</em> parece apropiado, y el error refleja ruido en nuestra medición. El modelo lineal especifica que la relación entre dos variables sigue una línea recta. Por ejemplo, en un modelo lineal, un incremento particular en el contenido de alcohol en la sangre (BAC) siempre es asociado con un aumento específico en el tiempo de reacción, independientemente del nivel de contenido de alcohol en la sangre (BAC).</p>
<!--On the other hand, there are other situations where the linear model is incorrect, and error will be increased because the model is not properly specified.  Let's say that we are interested in the relationship between caffeine intake and performance on a test.  The relation between stimulants like caffeine and test performance is often *nonlinear* - that is, it doesn't follow a straight line.  This is because performance goes up with smaller amounts of caffeine (as the person becomes more alert), but then starts to decline with larger amounts (as the person becomes nervous and jittery). We can simulate data of this form, and then fit a linear model to the data (see Panel C of Figure \@ref(fig:BACrt)). The blue line shows the straight line that best fits these data; clearly, there is a high degree of error.  Although there is a very lawful relation between test performance and caffeine intake, it follows a curve rather than a straight line.  The linear model has high error because it's the wrong model for these data.-->
<p>Por otro lado, hay situaciones en donde el modelo lineal es incorrecto, y el error va a incrementar porque el modelo no está correctamente especificado. Digamos que estamos interesadxs en la relación entre la ingesta de cafeína y el rendimiento en un examen. La relación entre estimulantes como la cafeína y el rendimiento en un examen es a menudo <em>no lineal</em> - esto quiere decir que no sigue una línea recta. Esto es porque el rendimiento sube con cantidades pequeñas de cafeína (conforme la persona se pone más alerta), pero después empieza a declinar con cantidades grandes (conforme la persona se pone más nerviosa). Podemos simular datos de esta forma, y luego ajustar un modelo lineal a los datos (observa el Panel C de la Figura <a href="fitting-models.html#fig:BACrt">5.5</a>). La línea azul muestra una línea recta que mejor se ajusta a estos datos; claramente, hay un alto margen de error. Aunque existe una relación entre el rendimiento de la prueba y la ingesta de cafeína, sigue a una curva en lugar de a una línea recta. El modelo lineal tiene mayor error porque es el modelo incorrecto para este tipo de datos.</p>
<!--## Can a model be too good? {#overfitting}-->
</div>
<div id="overfitting" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> ¿Un modelo puede ser demasiado bueno?</h2>
<!--Error sounds like a bad thing, and usually we will prefer a model that has lower error over one that has higher error. However, we mentioned above that there is a tension between the ability of a model to accurately fit the current dataset and its ability to generalize to new datasets, and it turns out that the model with the lowest error often is much worse at generalizing to new datasets!-->
<p>Un error suena como algo malo, y usualmente vamos a preferir un modelo que tenga menor error a uno que tenga mayor error. No obstante, ya mencionamos que existe tensión entre la habilidad de un modelo para ajustarse correctamente a un conjunto de datos en particular y su habilidad para generalizarse a nuevos conjuntos de datos… ¡Y resulta ser que el modelo con el menor error es a menudo peor para generalizarse a nuevos conjuntos de datos!</p>
<!--To see this, let's once again generate some data so that we know the true relation between the variables.  We will create two simulated datasets, which are generated in exactly the same way -- they just have different random noise added to them.-->
<p>Para ver esto, hay que generar de nuevo un conjunto de datos para que podamos conocer la verdadera relación entre las variables. Crearemos dos conjuntos de datos simulados, los cuales se generarán de la misma manera exacta – solamente que van a tener diferente ruido aleatorio añadido a ellos.</p>
<div class="figure"><span id="fig:Overfitting"></span>
<img src="StatsThinking21_files/figure-html/Overfitting-1.png" alt="An example of overfitting. Both datasets were generated using the same model, with different random noise added to generate each set.  The left panel shows the data used to fit the model, with a simple linear fit in blue and a complex (8th order polynomial) fit in red.  The root mean square error (RMSE) values for each model are shown in the figure; in this case, the complex model has a lower RMSE than the simple model.  The right panel shows the second dataset, with the same model overlaid on it and the RMSE values computed using the model obtained from the first dataset.  Here we see that the simpler model actually fits the new dataset better than the more complex model, which was overfitted to the first dataset." width="768" height="50%" />
<p class="caption">
Figura 5.6: An example of overfitting. Both datasets were generated using the same model, with different random noise added to generate each set. The left panel shows the data used to fit the model, with a simple linear fit in blue and a complex (8th order polynomial) fit in red. The root mean square error (RMSE) values for each model are shown in the figure; in this case, the complex model has a lower RMSE than the simple model. The right panel shows the second dataset, with the same model overlaid on it and the RMSE values computed using the model obtained from the first dataset. Here we see that the simpler model actually fits the new dataset better than the more complex model, which was overfitted to the first dataset.
</p>
</div>
<!--The left panel in Figure \@ref(fig:Overfitting) shows that the more complex model (in red) fits the data better than the simpler model (in blue).  However, we see the opposite when the same model is applied to a new dataset generated in the same way -- here we see that the simpler model fits the new data better than the more complex model.  Intuitively, we can see that the more complex model is influenced heavily by the specific data points in the first dataset; since the exact position of these data points was driven by random noise, this leads the more complex model to fit badly on the new dataset. This is a phenomenon that we call *overfitting*. For now it's important to keep in mind that our model fit needs to be good, but not too good. As Albert Einstein (1933) said: "It can scarcely be denied that the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience." Which is often paraphrased as: "Everything should be as simple as it can be, but not simpler."-->
<p>El panel de la izquierda en la Figura <a href="fitting-models.html#fig:Overfitting">5.6</a> muestra que el modelo más complejo (en rojo) se ajusta a los datos mejor que el modelo simple (en azul) generado en la misma manera– aquí podemos observar que el modelo más simple se ajusta mejor al nuevo conjunto de datos que el modelo complejo. Intuitivamente podemos observar que el modelo complejo está influenciado por los puntos specíficos de los datos en el primer conjunto de datos; dado que la posición exacta de estos puntos de datos fue impulsada por ruido aleatorio, esto lleva al modelo complejo a ajustarse mal en el nuevo conjunto de datos. A este fenómeno lo llamamos <em>sobreajuste</em> (<em>overfitting</em> en inglés). Por ahora es importante que mantengamos en mente que nuestro modelo debe ajustarse bien, pero no demasiado bien. Como lo dijo alguna vez Albert Einstein (1933): “Difícilmente se puede negar que el fin supremo de toda teoría es hacer que los elementos básicos irreductibles sean lo más simples y pocos posibles sin tener que renunciar a la representación adecuada de un solo dato de experiencia.” Lo cual se parafrasea a: “Todo debe de ser tan simple como pueda ser, pero no más simple.”</p>
<!--## The simplest model: The mean-->
</div>
<div id="el-modelo-más-simple-la-media" class="section level2" number="5.5">
<h2><span class="header-section-number">5.5</span> El modelo más simple: La media</h2>
<!--We have already encountered the mean (or average), and in fact most people know about the average even if they have never taken a statistics class. It is commonly used to describe what we call the "central tendency" of a dataset -- that is, what value are the data centered around?  Most people don't think of computing a mean as fitting a model to data.  However, that's exactly what we are doing when we compute the mean.-->
<p>Ya nos hemos encontrado con la media (o promedio), y de hecho, la mayoría de las personas conoce qué es un promedio, incluso si nunca han tomado una clase de estadística. Es más comunmente usado para describir lo que llamamos la “tendencia central” del conjunto de datos – ¿cuál es el valor en el que se centran los datos? La mayoría de las personas no piensa que calcular una media es ajustar un modelo a los datos. Sin embargo, eso es exactamente lo que estamos haciendo cuando calculamos la media.</p>
<!--We have already seen the formula for computing the mean of a sample of data:-->
<p>Ya hemos revisado la formula para calcular la media de una muestra de datos:</p>
<p><span class="math display">\[
\bar{X} = \frac{\sum_{i=1}^{n}x_i}{n}
\]</span></p>
<!--Note that I said that this formula was specifically for a *sample* of data, which is a set of data points selected from a larger population. Using a sample, we wish to characterize a larger population -- the full set of individuals that we are interested in. For example, if we are a political pollster our population of interest might be all registered voters, whereas our sample might just include a few thousand people sampled from this population.  Later in the course we will talk in more detail about sampling, but for now the important point is that statisticians generally like to use different symbols to differentiate *statistics* that describe values for a sample from *parameters* that describe the true values for a population; in this case, the formula for the population mean (denoted as $\mu$) is:-->
<p>Nota que dije que esta fórmula es específica para una <em>muestra</em> de datos, lo cual es un grupo de datos seleccionados de una población más grande. Usando una muestra, deseamos caracterizar una población más grande – el conjunto total de individuos en lxs que estamos interesadxs. Por ejemplo, si fuéramos unx encuestadxr político nuestra población de interés tal vez serían todxs lxs votantes registradxs, mientras que nuestra muestra podría incluir solo unos pocos miles de personas de esta población. Más adelante en este curso estaremos hablando con más detalle sobre el muestreo, pero por ahora el punto importante es que a lxs estadísticxs generalmente les gusta usar diferentes símbolos para diferenciar <em>estadísticas</em> que describen valores para una muestra de <em>parámetros</em> que describen los valores verdaderos para una población; en este caso la fórmula para la media (denotada como <span class="math inline">\(\mu\)</span>) de la población es:</p>
<p><span class="math display">\[
\mu = \frac{\sum_{i=1}^{N}x_i}{N}
\]</span></p>
<!--where N is the size of the entire population.-->
<p>donde N es el tamaño de la población completa.</p>
<!--We have already seen that the mean is the summary statistic that is guaranteed to give us an average error of zero.  The mean also has another characteristic: It is the summary statistic that has the lowest possible value for the sum of squared errors (SSE). In statistics, we refer to this as being the "best" estimator. We could prove this mathematically, but instead we will demonstrate it graphically in Figure \@ref(fig:MinSSE).-->
<p>Ya hemos visto que la media es el resumen estadístico que nos garantiza darnos un error promedio de cero. La media también tiene otra característica: es el resumen estadístico que tiene el valor más bajo posible para la suma de errores cuadráticos (SSE, <em>sum of squared errors</em>). En estadística, nos referimos a esto como el “mejor” estimador . Podríamos probarlo matemáticamente, pero en su lugar vamos a demostrarlo gráficamente en la Figura <a href="fitting-models.html#fig:MinSSE">5.7</a>.</p>
<!--```{r MinSSE, echo=FALSE,fig.cap="A demonstration of the mean as the statistic that minimizes the sum of squared errors.  Using the NHANES child height data, we compute the mean (denoted by the blue bar). Then, we test a range of other values, and for each one we compute the sum of squared errors for each data point from that value, which are denoted by the black curve.  We see that the mean falls at the minimum of the squared error plot.",fig.width=4,fig.height=4,out.height='50%'}-->
<div class="figure"><span id="fig:MinSSE"></span>
<img src="StatsThinking21_files/figure-html/MinSSE-1.png" alt="Una demostración de la media como la estadística que minimiza la suma de los errores cuadráticos. Utilizando los datos de la altura del NHANES, calculamos la media (la barra azul). Luego, probamos un rango de otros valores, y por cada uno calculamos la suma de errores cuadráticos por cada dato de ese valor, el cual se indica por la curva negra. Vemos que la media cae al mínimo en la gráfica del error cuadrático." width="384" height="50%" />
<p class="caption">
Figura 5.7: Una demostración de la media como la estadística que minimiza la suma de los errores cuadráticos. Utilizando los datos de la altura del NHANES, calculamos la media (la barra azul). Luego, probamos un rango de otros valores, y por cada uno calculamos la suma de errores cuadráticos por cada dato de ese valor, el cual se indica por la curva negra. Vemos que la media cae al mínimo en la gráfica del error cuadrático.
</p>
</div>
<!--This minimization of SSE is a good feature, and it's why the mean is the most commonly used statistic to summarize data.  However, the mean also has a dark side.  Let's say that five people are in a bar, and we examine each person's  income:-->
<p>El minimizar la suma de los errores cuadráticos (SSE) es una buena característica, y es la razón por la que la media es el estadístico más comunmente usado para resumir datos. No obstante, la media también tiene su lado oscuro. Digamos que hay cinco personas en un bar, y examinamos el ingreso económico de cada unx:</p>
<table>
<caption><span id="tab:unnamed-chunk-17">Tabla 5.1: </span>Income for our five bar patrons</caption>
<thead>
<tr class="header">
<th align="right">income</th>
<th align="left">person</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">48000</td>
<td align="left">Joe</td>
</tr>
<tr class="even">
<td align="right">64000</td>
<td align="left">Karen</td>
</tr>
<tr class="odd">
<td align="right">58000</td>
<td align="left">Mark</td>
</tr>
<tr class="even">
<td align="right">72000</td>
<td align="left">Andrea</td>
</tr>
<tr class="odd">
<td align="right">66000</td>
<td align="left">Pat</td>
</tr>
</tbody>
</table>
<!--The mean (61600.00) seems to be a pretty good summary of the income of those five people.  Now let's look at what happens if Beyoncé Knowles walks into the bar:-->
<p>La media (61600.00) parece ser una buena herramienta para medir el ingreso económico de esas cinco personas. Ahora observemos lo que pasa cuando Beyoncé Knowles entra al bar (además de la emoción de todxs):</p>
<table>
<caption><span id="tab:unnamed-chunk-19">Tabla 5.2: </span>Income for our five bar patrons plus Beyoncé Knowles.</caption>
<thead>
<tr class="header">
<th align="left">income</th>
<th align="left">person</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">48000</td>
<td align="left">Joe</td>
</tr>
<tr class="even">
<td align="left">64000</td>
<td align="left">Karen</td>
</tr>
<tr class="odd">
<td align="left">58000</td>
<td align="left">Mark</td>
</tr>
<tr class="even">
<td align="left">72000</td>
<td align="left">Andrea</td>
</tr>
<tr class="odd">
<td align="left">66000</td>
<td align="left">Pat</td>
</tr>
<tr class="even">
<td align="left">54000000</td>
<td align="left">Beyonce</td>
</tr>
</tbody>
</table>
<!--The mean is now almost 10 million dollars, which is not really representative of any of the people in the bar -- in particular, it is heavily driven by the outlying value of Beyoncé.  In general, the mean is highly sensitive to extreme values, which is why it's always important to ensure that there are no extreme values when using the mean to summarize data.-->
<p>La media es ahora casi 10 millones de dólares, lo cual no es verdaderamente representativo de lo que ganan las primeras cinco personas que estaban en el bar – en particular, la media está altamente influenciada por el valor extremo de Beyoncé. En general, la media es altamente sensible a valores extremos. Es por eso que siempre es importante asegurarnos de que no haya valores extremos cuando utilicemos la media para resumir datos.</p>
<!--### The median-->
<div id="la-mediana" class="section level3" number="5.5.1">
<h3><span class="header-section-number">5.5.1</span> La mediana</h3>
<!--If we want to summarize the data in a way that is less sensitive to outliers, we can use another statistic called the *median*.  If we were to sort all of the values in order of their magnitude, then the median is the value in the middle.  If there is an even number of values then there will be two values tied for the middle place, in which case we take the mean (i.e. the halfway point) of those two numbers.-->
<p>Si queremos resumir los datos en una forma que sea menos sensible a valores atípicos, podemos utilizar otra herramienta estadística llamada la <em>mediana</em>. Si nuestro propósito fuera acomodar todos los valores en orden de su magnitud, entonces la mediana es el valor que queda en medio. Si hay un número par de valores, entonces habrá dos valores empatados para el lugar medio, en cuyo caso tomamos la media (es decir, el punto medio) de esos dos números.</p>
<!--Let's look at an example.  Say we want to summarize the following values:-->
<p>Veamos un ejemplo: Digamos que queremos resumir los siguientes valores:</p>
<pre><code>8  6  3 14 12  7  6  4  9</code></pre>
<!--If we sort those values:-->
<p>Si ordenamos dichos valores:</p>
<pre><code>3  4  6  6  7  8  9 12 14</code></pre>
<!--Then the median is the middle value -- in this case, the 5th of the 9 values.-->
<p>Entonces la mediana es el valor de en medio – en este caso, el quinto de los nueve valores.</p>
<!--Whereas the mean minimizes the sum of squared errors, the median minimizes a slighty different quantity: The sum of *absolute* errors.  This explains why it is less sensitive to outliers -- squaring is going to exacerbate the effect of large errors compared to taking the absolute value.  We can see this in the case of the income example: The median is much more representative of the group as a whole, and less sensitive to the one large outlier.-->
<p>Mientras que la media minimiza la suma de los errores cuadráticos, la mediana minimiza una cantidad ligeramente distinta: la suma de los errores <em>absolutos</em> (absolute errors). Esto explica por qué es menos sensible a valores atípicos – elevar al cuadrado va a exacerbar el efecto de errores grandes en comparación con tomar el valor absoluto. Podemos ver esto en el caso del ingreso económico: la mediana es mucho más representativa de todo el grupo, y menos sensible a un valor atípico.</p>
<table>
<caption><span id="tab:unnamed-chunk-20">Tabla 5.3: </span>Summary statistics for income after arrival of Beyoncé Knowles.</caption>
<thead>
<tr class="header">
<th align="left">Statistic</th>
<th align="right">Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Mean</td>
<td align="right">9051333</td>
</tr>
<tr class="even">
<td align="left">Median</td>
<td align="right">65000</td>
</tr>
</tbody>
</table>
<!--Given this, why would we ever use the mean?  As we will see in a later chapter, the mean is the "best" estimator in the sense that it will vary less from sample to sample compared to other estimators.  It's up to us to decide whether that is worth the sensitivity to potential outliers -- statistics is all about tradeoffs.-->
<p>Dado esto, ¿por qué utilizaríamos entonces la media? Como veremos más adelante en este capítulo, la media es el “mejor” estimador en el sentido de que varía menos de muestra en muestra en comparación con otros estimadores. Queda en nosotrxs decidir si vale la pena su sensibilidad a posibles valores atípicos – la estadística se trata de balancear ventajas y desventajas.</p>
<!--## The mode-->
</div>
</div>
<div id="la-moda" class="section level2" number="5.6">
<h2><span class="header-section-number">5.6</span> La moda</h2>
<!--Sometimes we wish to describe the central tendency of a dataset that is not numeric.  For example, let's say that we want to know which models of iPhone are most commonly used.  To test this, we could ask a large group of iPhone users which model each person owns. If we were to take the average of these values, we might see that the mean iPhone model is 9.51, which is clearly nonsensical, since the iPhone model numbers are not meant to be quantitative measurements. In this case, a more appropriate measure of central tendency is the mode, which is the most common value in the dataset, as we discussed above.-->
<p>A veces deseamos describir la tendencia central de un conjunto de datos que no es numérico. Por ejemplo, digamos que queremos saber cuáles modelos de iPhones son más comunmente usados. Para probar esto, podemos preguntarle a un grupo grande de usuarios de iPhone cuál modelo es el que cada unx tiene. Si sacáramos el promedio de esos valores posiblemente veamos que la media del modelo de iPhone sería 9.51, lo cual no tiene sentido, ya que, el número de modelo de iPhone no están diseñados para ser mediciones cuantitativas. En este caso, una medición de tendencia central más apropiada es la moda, cuál es el valor más común en el conjunto de datos.</p>
<!--## Variability: How well does the mean fit the data?-->
</div>
<div id="variabilidad-qué-tan-bien-se-ajusta-la-media-a-los-datos" class="section level2" number="5.7">
<h2><span class="header-section-number">5.7</span> Variabilidad: ¿Qué tan bien se ajusta la media a los datos?</h2>
<!--Once we have described the central tendency of the data, we often also want to describe how variable the data are -- this is sometimes also referred to as "dispersion", reflecting the fact that it describes how widely dispersed the data are.-->
<p>Una vez que hemos descrito la tendencia central de los datos, a menudo también vamos a querer describir qué tan variables son los datos – a esto se le refiere también como “dispersión”, reflejando el hecho de que describe qué tan dispersos están los datos.</p>
<!--We have already encountered the sum of squared errors above, which is the basis for the most commonly used measures of variability: the *variance* and the *standard deviation*.  The variance for a population (referred to as $\sigma^2$) is simply the sum of squared errors divided by the number of observations - that is, it is exactly the same as the *mean squared error* that you encountered earlier:-->
<p>Ya hemos encontrado la suma de errores cuadráticos arriba, lo cual es la base para las mediciones más comunmente usadas para la variablidad: la <em>varianza</em> y la <em>desviación estándar</em>. La varianza para una población (referida como <span class="math inline">\(\sigma^2\)</span>) es simplemente la suma de los errores cuadráticos divididos entre el número de observaciones– lo cual es exactamente lo mismo que el <em>error cuadrático medio</em> del que hablamos hace poco:</p>
<p><span class="math display">\[
\sigma^2 = \frac{SSE}{N} = \frac{\sum_{i=1}^n (x_i - \mu)^2}{N}
\]</span></p>
<!--where $\mu$ is the population mean. The standard deviation is simply the square root of this -- that is, the *root mean squared error* that we saw before.  The standard deviation is useful because the errors are in the same units as the original data (undoing the squaring that we applied to the errors).-->
<p>donde <span class="math inline">\(\mu\)</span> es la media de la población. La desviación estándar es simplemente la raíz cuadrada de esto – es la <em>raíz del error cuadrático medio</em> que vimos antes. La desviación estándar es útil porque los errores están en las mismas unidades que en los datos originales (al deshacer el cuadrado que aplicamos a los errores).</p>
<!--We usually don't have access to the entire population, so we have to compute the variance using a sample, which we refer to as $\hat{\sigma}^2$, with the "hat" representing the fact that this is an estimate based on a sample. The equation for  $\hat{\sigma}^2$ is similar to the one for  $\sigma^2$:-->
<p>Usualmente no tenemos acceso a toda la población, por lo que debemos calcular la varianza utilizando una muestra, a la cual nos referimos como <span class="math inline">\(\hat{\sigma}^2\)</span>, con el “sombrero” representando el hecho de que es un estimado basado en una muestra. La ecuación para <span class="math inline">\(\hat{\sigma}^2\)</span> es similar a la de <span class="math inline">\(\sigma^2\)</span>:</p>
<p><span class="math display">\[
\hat{\sigma}^2 = \frac{\sum_{i=1}^N (x_i - \bar{X})^2}{n-1}
\]</span></p>
<!--The only difference between the two equations is that we divide by n - 1 instead of N. This relates to a fundamental statistical concept: *degrees of freedom*.  Remember that in order to compute the sample variance, we first had to estimate the sample mean $\bar{X}$.  Having estimated this, one value in the data is no longer free to vary.  For example, let's say we have the following data points for a variable $x$: [3, 5, 7, 9, 11], the mean of which is 7. Because we know that the mean of this dataset is 7, we can compute what any specific value would be if it were missing. For example, let's say we were to obscure the first value (3). Having done this, we still know that its value must be 3, because the mean of 7 implies that the sum of all of the values is $7 * n = 35$ and $35 - (5 + 7 + 9 + 11) = 3$.-->
<p>La única diferencia entre las dos ecuaciones es que dividimos entre <span class="math inline">\(n - 1\)</span> en lugar de <span class="math inline">\(N\)</span>. Esto se relaciona con un concepto estadístico fundamental: <em>grados de libertad</em>. Recuerda que para calcular la varianza de la muestra, primero tuvimos que estimar la media de la muestra <span class="math inline">\(\bar{X}\)</span>. Al haber estimado esto, un valor en los datos ya no puede variar libremente. Por ejemplo, digamos que tenemos los siguientes datos para una variable <span class="math inline">\(x\)</span>: [3, 5, 7, 9, 11], la media es 7. Porque sabemos que la media de este conjunto de datos es 7, podemos calcular cuál sería cualquier valor específico si faltara. Por ejemplo, digamos que ocultamos el primer valor (3). Al hacer esto, aún sabemos que su valor debe de ser 3, porque la media de 7 implica que la suma de todos los valores es <span class="math inline">\(7 * n = 35\)</span> y <span class="math inline">\(35 - (5 + 7 + 9 + 11) = 3\)</span>.</p>
<!--So when we say that we have "lost" a degree of freedom, it means that there is a value that is not free to vary after fitting the model.  In the context of the sample variance, if we don't account for the lost degree of freedom, then our estimate of the sample variance will be *biased*, causing us to underestimate the uncertainty of our estimate of the mean.-->
<p>Entonces, cuando decimos que hemos “perdido” un grado de libertad, quiere decir que hay un valor que no puede variar libremente después de haberse acomodado al modelo. En el contexto de la varianza de la muestra, si no contemplamos la pérdida de grados de libertad, entonces nuestra estimación de la varianza de la muestra estará <em>sesgada</em>, ocasionando que subestimemos la incertidumbre de nuestra estimación de la media.</p>
<!--## Using simulations to understand statistics-->
</div>
<div id="usar-simulaciones-para-entender-la-estadística" class="section level2" number="5.8">
<h2><span class="header-section-number">5.8</span> Usar simulaciones para entender la estadística</h2>
<!--I am a strong believer in the use of computer simulations to understand statistical concepts, and in later chapters we will dig deeply into their use.  Here we will introduce the idea by asking whether we can confirm the need to subtract 1 from the sample size in computing the sample variance.-->
<p>Soy un ávido creyente en el uso de simulaciones en computadora para comprender conceptos de estadística, y en capítulos futuros ahondaremos más en su uso. Aquí les presentaré la idea preguntándoles si podemos confirmar la necesidad de restar 1 del tamaño de la muestra al calcular la varianza de la muestra.</p>
<!--Let's treat the entire sample of children from the NHANES data as our "population", and see how well the calculations of sample variance using either $n$ or $n-1$ in the denominator will estimate variance of this population, across a large number of simulated random samples from the data.  We will return to the details of how to do this in a later chapter.-->
<p>Usemos la muestra completa de los datos de lxs niñxs de NHANES como nuestra “población”, y observemos qué tan bien los cálculos de la varianza de la muestra utilizando tanto <span class="math inline">\(n\)</span> como <span class="math inline">\(n-1\)</span> en el denominador estimará la varianza de esta población a lo largo de un gran número de muestras simuladas aleatorias obtenidas del conjunto de datos. Regresaremos a los detalles de cómo se hace esto en un capítulo próximo.</p>
<table>
<caption><span id="tab:unnamed-chunk-22">Tabla 5.4: </span>Variance estimates using n versus n-1; the estimate using n-1 is closer to the population value</caption>
<thead>
<tr class="header">
<th align="left">Estimate</th>
<th align="right">Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Population variance</td>
<td align="right">725</td>
</tr>
<tr class="even">
<td align="left">Variance estimate using n</td>
<td align="right">710</td>
</tr>
<tr class="odd">
<td align="left">Variance estimate using n-1</td>
<td align="right">725</td>
</tr>
</tbody>
</table>
<!--This shows us that the theory outlined above was correct: The variance estimate using $n - 1$ as the denominator is very close to the variance computed on the full data (i.e, the population), whereas the variance computed using $n$ as the denominator is biased (smaller) compared to the true value.-->
<p>Esto nos demuestra que la teoría propuesta arriba era correcta: la varianza estimada utilizando <span class="math inline">\(n - 1\)</span> como el denominador se acerca mucho a la varianza calculada con todos los datos (la población), por lo que la varianza calculada utilizando <span class="math inline">\(n\)</span> como el denominador está sesgada en comparación con el valor real.</p>
<!--## Z-scores-->
</div>
<div id="puntajes-z" class="section level2" number="5.9">
<h2><span class="header-section-number">5.9</span> Puntajes Z</h2>
<!--Having characterized a distribution in terms of its central tendency and variability, it is often useful to express the individual scores in terms of where they sit with respect to the overall distribution.  Let's say that we are interested in characterizing the relative level of crimes across different states, in order to determine whether California is a particularly dangerous place. We can ask this question using data for 2014 from the [FBI's Uniform Crime Reporting site](https://www.ucrdatatool.gov/Search/Crime/State/RunCrimeOneYearofData.cfm). The left panel of Figure \@ref(fig:crimeHist) shows a histogram of the number of violent crimes per state, highlighting the value for California. Looking at these data, it seems like California is terribly dangerous, with 153709 crimes in that year.  We can visualize these data by generating a map showing the distribution of a variable across states, which is presented in the right panel of Figure \@ref(fig:crimeHist).-->
<p>Habiendo caracterizado una distribución en términos de su tendencia central y su variabilidad, a menudo es útil expresar los puntajes individuales en términos de en dónde se ubican con respecto a la distribución total. Digamos que estamos interesadxs en determinar si California es un lugar particularmente peligroso. Podemos responder a esta pregunta utilizando datos del 2014 del [FBI’s Uniform Crime Reporting Site] (<a href="https://www.ucrdatatool.gov/Search/Crime/State/RunCrimeOneYearofData.cfm" class="uri">https://www.ucrdatatool.gov/Search/Crime/State/RunCrimeOneYearofData.cfm</a>).
El panel de la izquierda de la Figura <a href="fitting-models.html#fig:crimeHist">5.8</a> muestra un histograma del número de crímenes violentos por estado, resaltando el valor de California. Observando estos datos, parece que California es terriblemente peligroso, con 153709 crímenes en ese año.</p>
<p>Podemos visualizar estos datos al generar un mapa mostrando una distribución de la variable a lo largo de los estados, el cual se presenta en el panel de la derecha de la Figura <a href="fitting-models.html#fig:crimeHist">5.8</a>.</p>
<div class="figure"><span id="fig:crimeHist"></span>
<img src="StatsThinking21_files/figure-html/crimeHist-1.png" alt="Left: Histogram of the number of violent crimes.  The value for CA is plotted in blue. Right: A map of the same data, with number of crimes plotted for each state in color." width="768" height="50%" />
<p class="caption">
Figura 5.8: Left: Histogram of the number of violent crimes. The value for CA is plotted in blue. Right: A map of the same data, with number of crimes plotted for each state in color.
</p>
</div>
<!--It may have occurred to you, however, that CA also has the largest population of any state in the US, so it's reasonable that it will also have a larger number of crimes.  If we plot the number of crimes against one the population of each state (see left panel of Figure \@ref(fig:popVsCrime)), we see that there is a direct relationship between two variables.-->
<p>Tal vez hayas notado que California también tiene la población más grande de cualquier estado en Estados Unidos, por lo que es razonable que también tenga un gran número de crímenes. Si graficamos los números de crímenes junto con la población de cada estado (ve el panel izquierdo de la Figura <a href="fitting-models.html#fig:popVsCrime">5.9</a>), vemos que hay una relación directa entre las dos variables.</p>
<div class="figure"><span id="fig:popVsCrime"></span>
<img src="StatsThinking21_files/figure-html/popVsCrime-1.png" alt="Left: A plot of number of violent crimes versus population by state. Right: A histogram of per capita violent crime rates, expressed as crimes per 100,000 people." width="768" height="50%" />
<p class="caption">
Figura 5.9: Left: A plot of number of violent crimes versus population by state. Right: A histogram of per capita violent crime rates, expressed as crimes per 100,000 people.
</p>
</div>
<!--Instead of using the raw numbers of crimes, we should instead use the violent crime *rate* per capita, which we obtain by dividing the number of crimes per state by the population of each state.  The dataset from the FBI already includes this value (expressed as rate per 100,000 people). Looking at the right panel of Figure \@ref(fig:popVsCrime), we see that California is not so dangerous after all -- its crime rate of 396.10 per 100,000 people is a bit above the mean across states of 346.81, but well within the range of many other states. But what if we want to get a clearer view of how far it is from the rest of the distribution?-->
<p>En lugar de utilizar los números en bruto (o crudos) para los crímenes, debemos usar la <em>tasa</em> de crímenes violentos per cápita, el cual obtenemos al dividir el número de crímenes por estado entre la población de cada estado. El conjunto de datos del FBI ya incluye este valor (expresado como tasa por 100,000 habitantes). Observando el panel de la derecha de la Figura <a href="fitting-models.html#fig:popVsCrime">5.9</a>, podemos ver que California no es tan peligrosa después después de todo – su tasa de crímenes es 396.10 por cada 100,000 habitantes está un poco por arriba de la media de los estados de 346.81, pero está dentro del rango de muchos otros estados. ¿Pero qué pasa si queremos obtener una vista más clara de qué tanto se aleja California del resto de la distribución?</p>
<!--The *Z-score* allows us to express data in a way that provides more insight into each data point's relationship to the overall distribution.  The formula to compute a Z-score for an individual data point given that we know the value of the population mean $\mu$ and standard deviation $\sigma$ is:-->
<p>El <em>puntaje Z</em> (<em>Z-score</em>) nos permite expresar datos en una forma que proporciona más información sobre cada punto de datos y su relación con el total de la distribución. La fórmula que calcula el puntaje Z para un dato invididual, dado que ya conocemos el valor de la media de la población <span class="math inline">\(\mu\)</span> y su desviación estándar <span class="math inline">\(\sigma\)</span> es:</p>
<p><span class="math display">\[
Z(x) = \frac{x - \mu}{\sigma}
\]</span></p>
<!--Intuitively, you can think of a Z-score as telling you how far away any data point is from the mean, in units of standard deviation.  We can compute this for the crime rate data, as shown in Figure \@ref(fig:crimeZplot).-->
<p>Intuitivamente, podemos pensar en un puntaje Z como un indicador que nos dice qué tan lejos está cada punto o dato individual en referencia con la media, en unidades de la desviación estándar. Podemos calcular esto para los datos de la tasa de crímenes, como se muestra en la Figura <a href="fitting-models.html#fig:crimeZplot">5.10</a>.</p>
<div class="figure"><span id="fig:crimeZplot"></span>
<img src="StatsThinking21_files/figure-html/crimeZplot-1.png" alt="Scatterplot of original crime rate data against Z-scored data." width="384" height="50%" />
<p class="caption">
Figura 5.10: Scatterplot of original crime rate data against Z-scored data.
</p>
</div>
<!--The scatterplot shows us that the process of Z-scoring doesn't change the relative distribution of the data points (visible in the fact that the orginal data and Z-scored data fall on a straight line when plotted against each other) -- it just shifts them to have a mean of zero and a standard deviation of one. Figure \@ref(fig:crimeZmap) shows the Z-scored crime data using the geographical view.-->
<p>El diagrama de dispersión nos muestra que el proceso de sacar el puntaje Z no cambia la distribución relativa de los datos (esto es visible en el hecho de que los datos originales y el puntaje Z de los datos caen en una línea recta cuando se grafican una contra la otra).
Sólo las acomoda para que tengan una media de cero y una desviación estándar de uno. En la figura <a href="fitting-models.html#fig:crimeZmap">5.11</a> se muestran geográficamente los datos de crimen utilizando valores Z</p>
<div class="figure"><span id="fig:crimeZmap"></span>
<img src="StatsThinking21_files/figure-html/crimeZmap-1.png" alt="Crime data rendered onto a US map, presented as Z-scores." width="576" />
<p class="caption">
Figura 5.11: Crime data rendered onto a US map, presented as Z-scores.
</p>
</div>
<!--This provides us with a slightly more interpretable view of the data. For example, we can see that Nevada, Tennessee, and New Mexico all have crime rates that are roughly two standard deviations above the mean.-->
<p>Esto nos da una mirada un poco más interpretable de los datos. Por ejemplo, ahora podemos ver que Nevada, Tenessee y Nuevo México tienen tasas de crímenes que están aproximadamente dos desviaciones estándar por encima de la media.</p>
<!--### Interpreting Z-scores-->
<div id="interpretando-puntajes-z" class="section level3" number="5.9.1">
<h3><span class="header-section-number">5.9.1</span> Interpretando Puntajes Z</h3>
<!--The "Z" in "Z-score" comes from the fact that the standard normal distribution (that is, a normal distribution with a mean of zero and a standard deviation of 1) is often referred to as the "Z" distribution.  We can use the standard normal distribution to help us understand what specific Z scores tell us about where a data point sits with respect to the rest of the distribution.-->
<p>La “Z” en un “puntaje Z” proviene del hecho de que la distribución estándar normal (la distribución normal con una media de cero y una desviación estándar de 1) es a menudo referida como la distribución “Z”. Podemos usar la distribución estándar normal para ayudarnos a comprender lo que los puntajes Z específicos nos dicen acerca de dónde se encuentra un punto de datos con respecto al resto de la distribución.</p>
<div class="figure"><span id="fig:zDensityCDF"></span>
<img src="StatsThinking21_files/figure-html/zDensityCDF-1.png" alt="Density (top) and cumulative distribution (bottom) of a standard normal distribution, with cutoffs at one standard deviation above/below the mean." width="576" />
<p class="caption">
Figura 5.12: Density (top) and cumulative distribution (bottom) of a standard normal distribution, with cutoffs at one standard deviation above/below the mean.
</p>
</div>
<!--The upper panel in Figure \@ref(fig:zDensityCDF) shows that we expect about 16% of values to fall in $Z\ge 1$, and the same proportion to fall in $Z\le -1$.-->
<p>El panel de arriba en la Figura <a href="fitting-models.html#fig:zDensityCDF">5.12</a> muestra que esperamos que el 16% de los valores caigan en <span class="math inline">\(Z\ge 1\)</span>, y que la misma proporción caiga en <span class="math inline">\(Z\le -1\)</span>.</p>
<div class="figure"><span id="fig:zDensity2SD"></span>
<img src="StatsThinking21_files/figure-html/zDensity2SD-1.png" alt="Density (top) and cumulative distribution (bottom) of a standard normal distribution, with cutoffs at two standard deviations above/below the mean" width="576" />
<p class="caption">
Figura 5.13: Density (top) and cumulative distribution (bottom) of a standard normal distribution, with cutoffs at two standard deviations above/below the mean
</p>
</div>
<!--Figure \@ref(fig:zDensity2SD) shows the same plot for two standard deviations. Here we see that only about 2.3% of values fall in $Z \le -2$ and the same in $Z \ge 2$.  Thus, if we know the Z-score for a particular data point, we can estimate how likely or unlikely we would be to find a value at least as extreme as that value, which lets us put values into better context.  In the case of crime rates, we see that California has a Z-score of 0.38 for its violent crime rate per capita, showing that it is quite near the mean of other states, with about 35% of states having higher rates and 65% of states having lower rates.-->
<p>En la Figura <a href="fitting-models.html#fig:zDensity2SD">5.13</a> se muestra la misma gráfica para dos desviaciones estándar. Aquí podemos ver que solamente el 2.3% de los valores caen en <span class="math inline">\(Z \le -2\)</span> y lo mismo en <span class="math inline">\(Z \ge 2\)</span>. Por lo que, si conocemos el puntaje Z para un punto en particular de los datos podemos estimar qué tan probable o improbable sería encontrar un valor al menos tan extremo como ese valor, lo que nos permite poner los valores en un mejor contexto.</p>
<!--### Standardized scores-->
</div>
<div id="puntajes-estandarizados" class="section level3" number="5.9.2">
<h3><span class="header-section-number">5.9.2</span> Puntajes Estandarizados</h3>
<!--Let's say that instead of Z-scores, we wanted to generate standardized crime scores with a mean of 100 and standard deviation of 10.  This is similar to the standardization that is done with scores from intelligence tests to generate the intelligence quotient (IQ).  We can do this by simply multiplying the Z-scores by 10 and then adding 100.-->
<p>Digamos que en lugar de puntajes Z, queremos generar puntajes estandarizados de crimen con una media de 100 y una desviación estándar de 10. Esto es similar a la estandarización que se hace con puntajes de tests de inteligencia para generar un cociente inteligelectual (IQ, <em>Intelligence quotient</em>). Podemos hacer esto al multiplicar los puntajes Z por 10 y luego sumando 100.</p>
<div class="figure"><span id="fig:stdScores"></span>
<img src="StatsThinking21_files/figure-html/stdScores-1.png" alt="Crime data presented as standardized scores with mean of  100 and standard deviation of 10." width="384" height="50%" />
<p class="caption">
Figura 5.14: Crime data presented as standardized scores with mean of 100 and standard deviation of 10.
</p>
</div>
<!--#### Using Z-scores to compare distributions-->
<div id="usando-puntajes-z-para-comparar-distribuciones" class="section level4" number="5.9.2.1">
<h4><span class="header-section-number">5.9.2.1</span> Usando puntajes Z para comparar distribuciones</h4>
<!--One useful application of Z-scores is to compare distributions of different variables.  Let's say that we want to compare the distributions of violent crimes and property crimes across states.  In the left panel of  Figure \@ref(fig:crimeTypePlot) we plot those against one another, with CA plotted in blue. As you can see, the raw rates of property crimes are far higher than the raw rates of violent crimes, so we can't just compare the numbers directly.  However, we can plot the Z-scores for these data against one another (right panel of Figure \@ref(fig:crimeTypePlot))-- here again we see that the distribution of the data does not change.  Having put the data into Z-scores for each variable makes them comparable, and lets us see that California is actually right in the middle of the distribution in terms of both violent crime and property crime.-->
<p>Un uso útil de los puntajes Z es para comparar distribuciones de diferentes variables. Digamos que queremos comparar las distribuciones de crímenes violentos y crímenes en propiedades privadas entre estados. En el panel de la izquierda de la Figura <a href="fitting-models.html#fig:crimeTypePlot">5.15</a> graficamos ambos, uno contra el otro, con California representada en azul. Como puedes ver, las tasas brutas de delitos contra la propiedad son mucho más altos que las tasas brutas de crímenes violentos, por lo que no podemos solamente comparar los números directamente. Sin embargo, podemos graficar los puntajes Z para estos datos, uno contra otro (panel de la derecha de la Figura <a href="fitting-models.html#fig:crimeTypePlot">5.15</a>) – Aquí de nuevo podemos ver que la distribución de los datos no cambia. Al haber puesto los datos en puntajes Z para cada variable los hace comparables, y podemos ver ahora que California está justo en el medio de la distribución en términos de crímenes violentos y crímenes de propiedad privada.</p>
<div class="figure"><span id="fig:crimeTypePlot"></span>
<img src="StatsThinking21_files/figure-html/crimeTypePlot-1.png" alt="Plot of violent vs. property crime rates (left) and Z-scored rates (right)." width="768" height="50%" />
<p class="caption">
Figura 5.15: Plot of violent vs. property crime rates (left) and Z-scored rates (right).
</p>
</div>
<!--Let's add one more factor to the plot: Population.  In the left panel of Figure \@ref(fig:crimeTypePopPlot) we show this using the size of the plotting symbol, which is often a useful way to add information to a plot.-->
<p>Vamos a añadir otro factor a la gráfica: Población. En el panel izquierdo de la Figura <a href="fitting-models.html#fig:crimeTypePopPlot">5.16</a>, mostramos esto utilizando el tamaño del símbolo para graficar, el cual es comúnmente una forma útil de añadir información a la gráfica.</p>
<div class="figure"><span id="fig:crimeTypePopPlot"></span>
<img src="StatsThinking21_files/figure-html/crimeTypePopPlot-1.png" alt="Left: Plot of violent vs. property crime rates, with population size presented through the size of the plotting symbol; California is presented in blue. Right: Difference scores for violent vs. property crime, plotted against population. " width="768" height="50%" />
<p class="caption">
Figura 5.16: Left: Plot of violent vs. property crime rates, with population size presented through the size of the plotting symbol; California is presented in blue. Right: Difference scores for violent vs. property crime, plotted against population.
</p>
</div>
<!--Because Z-scores are directly comparable, we can also compute a *difference score* that expresses the relative rate of violent to non-violent (property) crimes across states. We can then plot those scores against population (see right panel of Figure \@ref(fig:crimeTypePopPlot)). This shows how we can use Z-scores to bring different variables together on a common scale.-->
<p>Porque los puntajes Z son directamente comparables, también podemos calcular <em>puntuaciones diferenciales</em> (<em>difference scores</em>), que expresen la tasa relativa de delitos violentos y no violentos (contra la propiedad) en todos los estados. Luego podemos graficar esos puntajes en comparación con la población (mira el Panel derecho de la Figura <a href="fitting-models.html#fig:crimeTypePopPlot">5.16</a>). Esto muestra cómo podemos usar los puntajes Z para unir diferentes variables en una escala común.</p>
<!--It is worth noting that the smallest states appear to have the largest differences in both directions. While it might be tempting to look at each state and try to determine why it has a high or low difference score, this probably  reflects the fact that the estimates obtained from smaller samples are necessarily going to be more variable, as we will discuss in the later chapter on Sampling.-->
<p>Vale la pena mencionar que los estados más pequeños parecen tener la diferencia más grande en ambas direcciones. Si bien puede ser tentador observar cada estado e intentar determinar por qué tiene una puntuación de diferencia alta o baja, esto probablemente refleja el hecho de que las estimaciones obtenidas de muestras más pequeñas necesariamente serán más variables, como discutiremos en un capítulo posterior sobre muestreo.</p>
<!--## Learning objectives-->
</div>
</div>
</div>
<div id="objetivos-de-aprendizaje-4" class="section level2" number="5.10">
<h2><span class="header-section-number">5.10</span> Objetivos de aprendizaje</h2>
<!--* Describe the basic equation for statistical models (outcome=model + error)
* Describe different measures of central tendency and dispersion, how they are computed, and which are appropriate under what circumstances.
* Compute a Z-score and describe why they are useful.-->
<p>Al leer este capítulo deberás de ser capaz de:</p>
<ul>
<li>Describir ecuaciones básicas para modelos estadísticos (outcome = model + error).</li>
<li>Describir diferentes mediciones de tendencia central y dispersión, cómo se calculan y cuáles son apropiadas bajo cuáles circunstancias.</li>
<li>Calcular puntajes Z y describir por qué son útiles.</li>
</ul>
<!--## Appendix-->
</div>
<div id="apéndice-1" class="section level2" number="5.11">
<h2><span class="header-section-number">5.11</span> Apéndice</h2>
<div id="proof-that-the-sum-of-errors-from-the-mean-is-zero" class="section level3" number="5.11.1">
<h3><span class="header-section-number">5.11.1</span> Proof that the sum of errors from the Mean is zero”</h3>
<p><span class="math display">\[
error = \sum_{i=1}^{n}(x_i - \bar{X}) = 0
\]</span></p>
<p><span class="math display">\[
\sum_{i=1}^{n}x_i - \sum_{i=1}^{n}\bar{X}=0
\]</span></p>
<p><span class="math display">\[
\sum_{i=1}^{n}x_i = \sum_{i=1}^{n}\bar{X}
\]</span></p>
<p><span class="math display">\[
\sum_{i=1}^{n}x_i = n\bar{X}
\]</span></p>
<p><span class="math display">\[
\sum_{i=1}^{n}x_i = \sum_{i=1}^{n}x_i
\]</span></p>

<!-- # Probability -->
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="data-visualization.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="probability.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="book_assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="book_assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="book_assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/statsthinking21/statsthinking21-core/edit/master/05-FittingModels.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["StatsThinking21.pdf", "StatsThinking21.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
